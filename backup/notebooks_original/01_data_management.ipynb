{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 数据管理模块 (Data Management)\n",
    "\n",
    "## 模块目标\n",
    "- 从AkShare获取14个金属期货品种的0指数连续合约历史数据（指数加权）\n",
    "- 建立本地数据仓库（Parquet格式）\n",
    "- 提供统一的数据访问接口\n",
    "- 支持增量更新\n",
    "\n",
    "## 14个期货品种\n",
    "- **贵金属**: AG0(银), AU0(金)\n",
    "- **有色金属**: AL0(铝), CU0(铜), NI0(镍), PB0(铅), SN0(锡), ZN0(锌)\n",
    "- **黑色系**: HC0(热卷), I0(铁矿), RB0(螺纹), SF0(硅铁), SM0(锰硅), SS0(不锈钢)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境设置和依赖安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AkShare版本: 1.17.35\n"
     ]
    }
   ],
   "source": [
    "# 安装必要的包\n",
    "!pip install akshare pandas numpy pyarrow matplotlib seaborn scipy statsmodels -q\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import logging\n",
    "import akshare as ak\n",
    "\n",
    "# 设置日志\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 设置pandas显示选项\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "print(f\"AkShare版本: {ak.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 配置管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据目录: F:\\metal verify\\notebooks\\..\\data\\futures\n"
     ]
    }
   ],
   "source": [
    "# 配置参数\n",
    "class Config:\n",
    "    \"\"\"数据管理配置\"\"\"\n",
    "    \n",
    "    # 14个期货品种代码\n",
    "    SYMBOLS = [\n",
    "        \"AG0\",  # 白银\n",
    "        \"AL0\",  # 铝\n",
    "        \"AU0\",  # 黄金\n",
    "        \"CU0\",  # 铜\n",
    "        \"HC0\",  # 热卷\n",
    "        \"I0\",   # 铁矿石\n",
    "        \"NI0\",  # 镍\n",
    "        \"PB0\",  # 铅\n",
    "        \"RB0\",  # 螺纹钢\n",
    "        \"SF0\",  # 硅铁\n",
    "        \"SM0\",  # 锰硅\n",
    "        \"SN0\",  # 锡\n",
    "        \"SS0\",  # 不锈钢\n",
    "        \"ZN0\",  # 锌\n",
    "    ]\n",
    "    \n",
    "    # 品种名称映射\n",
    "    SYMBOL_NAMES = {\n",
    "        \"AG0\": \"白银\",\n",
    "        \"AL0\": \"铝\",\n",
    "        \"AU0\": \"黄金\",\n",
    "        \"CU0\": \"铜\",\n",
    "        \"HC0\": \"热卷\",\n",
    "        \"I0\": \"铁矿石\",\n",
    "        \"NI0\": \"镍\",\n",
    "        \"PB0\": \"铅\",\n",
    "        \"RB0\": \"螺纹钢\",\n",
    "        \"SF0\": \"硅铁\",\n",
    "        \"SM0\": \"锰硅\",\n",
    "        \"SN0\": \"锡\",\n",
    "        \"SS0\": \"不锈钢\",\n",
    "        \"ZN0\": \"锌\",\n",
    "    }\n",
    "    \n",
    "    # 数据路径\n",
    "    DATA_DIR = Path(\"../data\")\n",
    "    FUTURES_DIR = DATA_DIR / \"futures\"\n",
    "    METADATA_FILE = DATA_DIR / \"metadata.json\"\n",
    "    UPDATE_LOG_FILE = DATA_DIR / \"update_log.csv\"\n",
    "    \n",
    "    # 数据字段\n",
    "    REQUIRED_COLUMNS = ['date', 'open', 'high', 'low', 'close', 'volume', 'open_interest']\n",
    "    \n",
    "    # API设置\n",
    "    RETRY_TIMES = 3\n",
    "    RETRY_DELAY = 5  # seconds\n",
    "\n",
    "# 创建数据目录\n",
    "Config.FUTURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"数据目录: {Config.FUTURES_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Story DM.1: 初始数据获取\n",
    "\n",
    "### REQ-DM.1.1: 批量获取14个品种的0指数连续合约日线数据\n",
    "### REQ-DM.1.2: 数据字段包含必需字段\n",
    "### REQ-DM.1.3: 使用Parquet格式存储\n",
    "### REQ-DM.1.4: 记录元信息到metadata.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 18:57:42,285 - INFO - 正在获取 RB0 (螺纹钢) 的数据...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始获取测试品种: ['RB0', 'HC0', 'I0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 18:57:42,720 - INFO - 成功获取 RB0 数据: 3982 条记录, 日期范围: 2009-03-27 至 2025-08-18\n",
      "2025-08-18 18:57:43,723 - INFO - 正在获取 HC0 (热卷) 的数据...\n",
      "2025-08-18 18:57:44,147 - INFO - 成功获取 HC0 数据: 2780 条记录, 日期范围: 2014-03-21 至 2025-08-18\n",
      "2025-08-18 18:57:45,158 - INFO - 正在获取 I0 (铁矿石) 的数据...\n",
      "2025-08-18 18:57:45,926 - INFO - 成功获取 I0 数据: 2879 条记录, 日期范围: 2013-10-18 至 2025-08-18\n",
      "2025-08-18 18:57:46,931 - INFO - 批量获取完成: 成功 3/3 个品种\n"
     ]
    }
   ],
   "source": [
    "# Cell name: fetch_history\n",
    "# Implements: REQ-DM.1.1, REQ-DM.1.2\n",
    "\n",
    "def fetch_single_symbol(symbol: str, retries: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    获取单个品种的期货连续合约历史数据\n",
    "    使用 ak.futures_zh_daily_sina API\n",
    "    \n",
    "    Args:\n",
    "        symbol: 品种代码，如'RB0'\n",
    "        retries: 重试次数\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with columns: date, open, high, low, close, volume, open_interest\n",
    "    \"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            logger.info(f\"正在获取 {symbol} ({Config.SYMBOL_NAMES.get(symbol, symbol)}) 的数据...\")\n",
    "            \n",
    "            # 使用正确的API: futures_zh_daily_sina\n",
    "            df = ak.futures_zh_daily_sina(symbol=symbol)\n",
    "            \n",
    "            if df is None or df.empty:\n",
    "                raise ValueError(f\"{symbol} 返回空数据\")\n",
    "            \n",
    "            # 重命名列：hold -> open_interest\n",
    "            df = df.rename(columns={'hold': 'open_interest'})\n",
    "            \n",
    "            # 选择需要的列\n",
    "            required_cols = ['date', 'open', 'high', 'low', 'close', 'volume', 'open_interest']\n",
    "            df = df[required_cols]\n",
    "            \n",
    "            # 数据类型转换\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            for col in ['open', 'high', 'low', 'close', 'volume', 'open_interest']:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            # 删除包含NaN的行\n",
    "            df = df.dropna(subset=['open', 'high', 'low', 'close'])\n",
    "            \n",
    "            # 按日期排序\n",
    "            df = df.sort_values('date').reset_index(drop=True)\n",
    "            \n",
    "            logger.info(f\"成功获取 {symbol} 数据: {len(df)} 条记录, \"\n",
    "                       f\"日期范围: {df['date'].min().date()} 至 {df['date'].max().date()}\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"获取 {symbol} 数据失败 (尝试 {attempt+1}/{retries}): {str(e)}\")\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(Config.RETRY_DELAY)\n",
    "            else:\n",
    "                raise RuntimeError(f\"无法获取 {symbol} 数据: {str(e)}\")\n",
    "\n",
    "\n",
    "def fetch_multiple_symbols(symbols: List[str]) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    批量获取多个品种的数据\n",
    "    \n",
    "    Args:\n",
    "        symbols: 品种代码列表\n",
    "        \n",
    "    Returns:\n",
    "        字典 {symbol: DataFrame}\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "    failed_symbols = []\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        try:\n",
    "            df = fetch_single_symbol(symbol)\n",
    "            data_dict[symbol] = df\n",
    "            time.sleep(1)  # 避免请求过快\n",
    "        except Exception as e:\n",
    "            logger.error(f\"获取 {symbol} 失败: {str(e)}\")\n",
    "            failed_symbols.append(symbol)\n",
    "    \n",
    "    if failed_symbols:\n",
    "        logger.warning(f\"失败的品种: {failed_symbols}\")\n",
    "    \n",
    "    logger.info(f\"批量获取完成: 成功 {len(data_dict)}/{len(symbols)} 个品种\")\n",
    "    \n",
    "    if not data_dict:\n",
    "        raise RuntimeError(\"没有成功获取任何数据\")\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "\n",
    "# 测试：获取核心品种数据\n",
    "test_symbols = ['RB0', 'HC0', 'I0']  # 先测试3个核心品种\n",
    "print(f\"\\n开始获取测试品种: {test_symbols}\")\n",
    "try:\n",
    "    test_data = fetch_multiple_symbols(test_symbols)\n",
    "except Exception as e:\n",
    "    print(f\"获取失败: {e}\")\n",
    "    test_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RB0 数据样本:\n",
      "        date    open    high     low   close  volume  open_interest\n",
      "0 2009-03-27  3550.0  3663.0  3513.0  3561.0  354590          45548\n",
      "1 2009-03-30  3550.0  3580.0  3528.0  3544.0  145168          48380\n",
      "2 2009-03-31  3538.0  3566.0  3531.0  3549.0   70592          44714\n",
      "3 2009-04-01  3560.0  3561.0  3543.0  3547.0   28100          42076\n",
      "4 2009-04-02  3545.0  3548.0  3456.0  3473.0  235446          68888\n",
      "\n",
      "数据信息:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3982 entries, 0 to 3981\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   date           3982 non-null   datetime64[ns]\n",
      " 1   open           3982 non-null   float64       \n",
      " 2   high           3982 non-null   float64       \n",
      " 3   low            3982 non-null   float64       \n",
      " 4   close          3982 non-null   float64       \n",
      " 5   volume         3982 non-null   int64         \n",
      " 6   open_interest  3982 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(4), int64(2)\n",
      "memory usage: 217.9 KB\n",
      "None\n",
      "\n",
      "数据统计:\n",
      "              open         high          low        close\n",
      "count  3982.000000  3982.000000  3982.000000  3982.000000\n",
      "mean   3690.286791  3724.727273  3656.192366  3690.514314\n",
      "std     789.601670   795.411236   781.940676   789.120202\n",
      "min    1628.000000  1642.000000  1618.000000  1626.000000\n",
      "25%    3320.000000  3352.000000  3294.250000  3326.000000\n",
      "50%    3707.000000  3738.500000  3676.500000  3708.000000\n",
      "75%    4153.750000  4187.750000  4118.000000  4154.000000\n",
      "max    6113.000000  6208.000000  5985.000000  6171.000000\n"
     ]
    }
   ],
   "source": [
    "# 显示数据样本\n",
    "if test_data:\n",
    "    first_symbol = list(test_data.keys())[0]\n",
    "    print(f\"\\n{first_symbol} 数据样本:\")\n",
    "    print(test_data[first_symbol].head())\n",
    "    print(f\"\\n数据信息:\")\n",
    "    print(test_data[first_symbol].info())\n",
    "    print(f\"\\n数据统计:\")\n",
    "    print(test_data[first_symbol][['open', 'high', 'low', 'close']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 18:58:06,890 - INFO - 成功保存 RB0 数据到 ..\\data\\futures\\RB0.parquet\n",
      "2025-08-18 18:58:06,924 - INFO - 成功保存 HC0 数据到 ..\\data\\futures\\HC0.parquet\n",
      "2025-08-18 18:58:06,938 - INFO - 成功保存 I0 数据到 ..\\data\\futures\\I0.parquet\n",
      "2025-08-18 18:58:06,938 - INFO - 批量保存完成: 3/3 个文件\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "保存了 3 个Parquet文件:\n",
      "  - RB0.parquet\n",
      "  - HC0.parquet\n",
      "  - I0.parquet\n"
     ]
    }
   ],
   "source": [
    "# Cell name: save_to_parquet\n",
    "# Implements: REQ-DM.1.3\n",
    "\n",
    "def save_to_parquet(df: pd.DataFrame, symbol: str, data_dir: Path = None) -> Path:\n",
    "    \"\"\"\n",
    "    将DataFrame保存为Parquet格式\n",
    "    \n",
    "    Args:\n",
    "        df: 数据DataFrame\n",
    "        symbol: 品种代码\n",
    "        data_dir: 保存目录\n",
    "        \n",
    "    Returns:\n",
    "        保存的文件路径\n",
    "    \"\"\"\n",
    "    if data_dir is None:\n",
    "        data_dir = Config.FUTURES_DIR\n",
    "    \n",
    "    file_path = data_dir / f\"{symbol}.parquet\"\n",
    "    \n",
    "    # 保存为Parquet格式\n",
    "    df.to_parquet(file_path, engine='pyarrow', compression='snappy', index=False)\n",
    "    logger.info(f\"成功保存 {symbol} 数据到 {file_path}\")\n",
    "    \n",
    "    # 验证保存的文件\n",
    "    test_df = pd.read_parquet(file_path)\n",
    "    assert len(test_df) == len(df), \"保存的数据行数不匹配\"\n",
    "    assert list(test_df.columns) == list(df.columns), \"保存的数据列不匹配\"\n",
    "    \n",
    "    return file_path\n",
    "\n",
    "\n",
    "def batch_save_to_parquet(data_dict: Dict[str, pd.DataFrame]) -> List[Path]:\n",
    "    \"\"\"\n",
    "    批量保存数据到Parquet文件\n",
    "    \n",
    "    Args:\n",
    "        data_dict: {symbol: DataFrame} 字典\n",
    "        \n",
    "    Returns:\n",
    "        保存的文件路径列表\n",
    "    \"\"\"\n",
    "    saved_files = []\n",
    "    \n",
    "    for symbol, df in data_dict.items():\n",
    "        try:\n",
    "            file_path = save_to_parquet(df, symbol)\n",
    "            saved_files.append(file_path)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"保存 {symbol} 失败: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    logger.info(f\"批量保存完成: {len(saved_files)}/{len(data_dict)} 个文件\")\n",
    "    return saved_files\n",
    "\n",
    "\n",
    "# 保存测试数据\n",
    "if test_data:\n",
    "    saved_files = batch_save_to_parquet(test_data)\n",
    "    print(f\"\\n保存了 {len(saved_files)} 个Parquet文件:\")\n",
    "    for file in saved_files:\n",
    "        print(f\"  - {file.name}\")\n",
    "else:\n",
    "    print(\"\\n没有数据可保存\")\n",
    "    saved_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 18:58:38,510 - INFO - 元信息已保存到 ..\\data\\metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "元信息已保存到: ..\\data\\metadata.json\n",
      "\n",
      "元信息内容:\n",
      "{\n",
      "  \"update_time\": \"2025-08-18T18:58:38.508669\",\n",
      "  \"symbols\": {\n",
      "    \"RB0\": {\n",
      "      \"name\": \"螺纹钢\",\n",
      "      \"fetch_time\": \"2025-08-18T18:58:38.508669\",\n",
      "      \"start_date\": \"2009-03-27T00:00:00\",\n",
      "      \"end_date\": \"2025-08-18T00:00:00\",\n",
      "      \"record_count\": 3982,\n",
      "      \"columns\": [\n",
      "        \"date\",\n",
      "        \"open\",\n",
      "        \"high\",\n",
      "        \"low\",\n",
      "        \"close\",\n",
      "        \"volume\",\n",
      "        \"open_interest\"\n",
      "      ],\n",
      "      \"file\": \"RB0.parquet\"\n",
      "    },\n",
      "    \"HC0\": {\n",
      "      \"name\": \"热卷\",\n",
      "      \"fetch_time\": \"2025-08-18T18:58:38.509669\",\n",
      "      \"start_date\": \"2014-03-21T00:00:00\",\n",
      "      \"end_date\": \"2025-08-18T00:00:00\",\n",
      "      \"record_count\": 2780,\n",
      "      \"columns\": [\n",
      "        \"date\",\n",
      "        \"open\",\n",
      "        \"high\",\n",
      "        \"low\",\n",
      "        \"close\",\n",
      "        \"volume\",\n",
      "        \"open_interest\"\n",
      "      ],\n",
      "      \"fil\n"
     ]
    }
   ],
   "source": [
    "# Cell name: save_metadata\n",
    "# Implements: REQ-DM.1.4\n",
    "\n",
    "def save_metadata(data_dict: Dict[str, pd.DataFrame]) -> Path:\n",
    "    \"\"\"\n",
    "    保存数据元信息到metadata.json\n",
    "    \n",
    "    Args:\n",
    "        data_dict: {symbol: DataFrame} 字典\n",
    "        \n",
    "    Returns:\n",
    "        metadata文件路径\n",
    "    \"\"\"\n",
    "    metadata = {\n",
    "        \"update_time\": datetime.now().isoformat(),\n",
    "        \"symbols\": {}\n",
    "    }\n",
    "    \n",
    "    for symbol, df in data_dict.items():\n",
    "        metadata[\"symbols\"][symbol] = {\n",
    "            \"name\": Config.SYMBOL_NAMES.get(symbol, symbol),\n",
    "            \"fetch_time\": datetime.now().isoformat(),\n",
    "            \"start_date\": df['date'].min().isoformat(),\n",
    "            \"end_date\": df['date'].max().isoformat(),\n",
    "            \"record_count\": len(df),\n",
    "            \"columns\": list(df.columns),\n",
    "            \"file\": f\"{symbol}.parquet\"\n",
    "        }\n",
    "    \n",
    "    # 保存metadata\n",
    "    with open(Config.METADATA_FILE, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    logger.info(f\"元信息已保存到 {Config.METADATA_FILE}\")\n",
    "    return Config.METADATA_FILE\n",
    "\n",
    "\n",
    "def load_metadata() -> Dict:\n",
    "    \"\"\"\n",
    "    加载元信息\n",
    "    \n",
    "    Returns:\n",
    "        元信息字典\n",
    "    \"\"\"\n",
    "    if Config.METADATA_FILE.exists():\n",
    "        with open(Config.METADATA_FILE, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "\n",
    "# 保存元信息\n",
    "if test_data:\n",
    "    metadata_file = save_metadata(test_data)\n",
    "    print(f\"\\n元信息已保存到: {metadata_file}\")\n",
    "    \n",
    "    # 显示元信息\n",
    "    metadata = load_metadata()\n",
    "    print(\"\\n元信息内容:\")\n",
    "    print(json.dumps(metadata, ensure_ascii=False, indent=2)[:800])\n",
    "else:\n",
    "    print(\"\\n没有元信息可保存\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Story DM.2: 增量数据更新\n",
    "\n",
    "### REQ-DM.2.1: 检测本地数据最后日期，仅获取新增数据\n",
    "### REQ-DM.2.2: 合并新旧数据，按日期去重\n",
    "### REQ-DM.2.3: 更新失败时回滚\n",
    "### REQ-DM.2.4: 生成更新日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 18:58:47,959 - INFO - RB0 本地数据最后日期: 2025-08-18\n",
      "2025-08-18 18:58:47,963 - INFO - HC0 本地数据最后日期: 2025-08-18\n",
      "2025-08-18 18:58:47,968 - INFO - I0 本地数据最后日期: 2025-08-18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RB0: 最后日期 2025-08-18\n",
      "HC0: 最后日期 2025-08-18\n",
      "I0: 最后日期 2025-08-18\n"
     ]
    }
   ],
   "source": [
    "# Cell name: detect_last_date\n",
    "# Implements: REQ-DM.2.1\n",
    "\n",
    "def detect_last_date(symbol: str) -> Optional[datetime]:\n",
    "    \"\"\"\n",
    "    检测本地数据的最后日期\n",
    "    \n",
    "    Args:\n",
    "        symbol: 品种代码\n",
    "        \n",
    "    Returns:\n",
    "        最后日期，如果文件不存在返回None\n",
    "    \"\"\"\n",
    "    file_path = Config.FUTURES_DIR / f\"{symbol}.parquet\"\n",
    "    \n",
    "    if not file_path.exists():\n",
    "        logger.info(f\"{symbol} 本地数据不存在\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_parquet(file_path)\n",
    "        last_date = df['date'].max()\n",
    "        logger.info(f\"{symbol} 本地数据最后日期: {last_date.date()}\")\n",
    "        return last_date\n",
    "    except Exception as e:\n",
    "        logger.error(f\"读取 {symbol} 本地数据失败: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# 测试检测最后日期\n",
    "if test_data:\n",
    "    for symbol in test_symbols:\n",
    "        last_date = detect_last_date(symbol)\n",
    "        if last_date:\n",
    "            print(f\"{symbol}: 最后日期 {last_date.date()}\")\n",
    "else:\n",
    "    print(\"没有数据可检测\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 18:58:57,079 - INFO - RB0 本地数据最后日期: 2025-08-18\n",
      "2025-08-18 18:58:57,081 - INFO - 开始更新 RB0 数据...\n",
      "2025-08-18 18:58:57,082 - INFO - 正在获取 RB0 (螺纹钢) 的数据...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "测试增量更新:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 18:58:57,619 - INFO - 成功获取 RB0 数据: 3982 条记录, 日期范围: 2009-03-27 至 2025-08-18\n",
      "2025-08-18 18:58:57,622 - INFO - RB0 无新数据\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RB0: 成功, 新增 0 条\n"
     ]
    }
   ],
   "source": [
    "# Cell name: update_incremental\n",
    "# Implements: REQ-DM.2.1, REQ-DM.2.2\n",
    "\n",
    "def update_incremental(symbol: str) -> Tuple[bool, int]:\n",
    "    \"\"\"\n",
    "    增量更新单个品种的数据\n",
    "    \n",
    "    Args:\n",
    "        symbol: 品种代码\n",
    "        \n",
    "    Returns:\n",
    "        (是否成功, 新增记录数)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 检测本地最后日期\n",
    "        last_date = detect_last_date(symbol)\n",
    "        \n",
    "        # 获取最新数据\n",
    "        logger.info(f\"开始更新 {symbol} 数据...\")\n",
    "        new_df = fetch_single_symbol(symbol)\n",
    "        \n",
    "        if last_date is None:\n",
    "            # 本地无数据，全部保存\n",
    "            save_to_parquet(new_df, symbol)\n",
    "            return True, len(new_df)\n",
    "        \n",
    "        # 筛选新增数据\n",
    "        new_records = new_df[new_df['date'] > last_date]\n",
    "        \n",
    "        if len(new_records) == 0:\n",
    "            logger.info(f\"{symbol} 无新数据\")\n",
    "            return True, 0\n",
    "        \n",
    "        # 加载本地数据\n",
    "        old_df = pd.read_parquet(Config.FUTURES_DIR / f\"{symbol}.parquet\")\n",
    "        \n",
    "        # 合并数据\n",
    "        combined_df = pd.concat([old_df, new_records], ignore_index=True)\n",
    "        \n",
    "        # 按日期去重（保留最新的）\n",
    "        combined_df = combined_df.drop_duplicates(subset=['date'], keep='last')\n",
    "        \n",
    "        # 按日期排序\n",
    "        combined_df = combined_df.sort_values('date').reset_index(drop=True)\n",
    "        \n",
    "        # 保存更新后的数据\n",
    "        save_to_parquet(combined_df, symbol)\n",
    "        \n",
    "        logger.info(f\"{symbol} 更新成功: 新增 {len(new_records)} 条记录\")\n",
    "        return True, len(new_records)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"{symbol} 更新失败: {str(e)}\")\n",
    "        return False, 0\n",
    "\n",
    "\n",
    "# 测试增量更新\n",
    "if test_data:\n",
    "    print(\"\\n测试增量更新:\")\n",
    "    for symbol in test_symbols[:1]:  # 测试一个品种\n",
    "        success, new_count = update_incremental(symbol)\n",
    "        print(f\"{symbol}: {'成功' if success else '失败'}, 新增 {new_count} 条\")\n",
    "else:\n",
    "    print(\"\\n跳过增量更新测试（无数据）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 18:59:09,755 - INFO - RB0 本地数据最后日期: 2025-08-18\n",
      "2025-08-18 18:59:09,759 - INFO - 正在获取 RB0 (螺纹钢) 的数据...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "测试原子性更新:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 18:59:10,225 - INFO - 成功获取 RB0 数据: 3982 条记录, 日期范围: 2009-03-27 至 2025-08-18\n",
      "2025-08-18 18:59:10,230 - INFO - RB0 无新数据\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RB0: 成功, 新增 0 条\n"
     ]
    }
   ],
   "source": [
    "# Cell name: atomic_update\n",
    "# Implements: REQ-DM.2.3\n",
    "\n",
    "def atomic_update(symbol: str) -> Tuple[bool, int]:\n",
    "    \"\"\"\n",
    "    原子性更新：使用临时文件确保更新失败时原数据不变\n",
    "    \n",
    "    Args:\n",
    "        symbol: 品种代码\n",
    "        \n",
    "    Returns:\n",
    "        (是否成功, 新增记录数)\n",
    "    \"\"\"\n",
    "    file_path = Config.FUTURES_DIR / f\"{symbol}.parquet\"\n",
    "    temp_path = Config.FUTURES_DIR / f\"{symbol}.parquet.tmp\"\n",
    "    backup_path = Config.FUTURES_DIR / f\"{symbol}.parquet.bak\"\n",
    "    \n",
    "    try:\n",
    "        # 检测本地最后日期\n",
    "        last_date = detect_last_date(symbol)\n",
    "        \n",
    "        # 获取最新数据\n",
    "        new_df = fetch_single_symbol(symbol)\n",
    "        \n",
    "        if last_date is not None:\n",
    "            # 加载旧数据\n",
    "            old_df = pd.read_parquet(file_path)\n",
    "            \n",
    "            # 只保留新增的数据\n",
    "            new_records = new_df[new_df['date'] > last_date]\n",
    "            \n",
    "            if len(new_records) == 0:\n",
    "                logger.info(f\"{symbol} 无新数据\")\n",
    "                return True, 0\n",
    "            \n",
    "            # 合并数据\n",
    "            combined_df = pd.concat([old_df, new_records], ignore_index=True)\n",
    "            combined_df = combined_df.drop_duplicates(subset=['date'], keep='last')\n",
    "            combined_df = combined_df.sort_values('date').reset_index(drop=True)\n",
    "            new_count = len(new_records)\n",
    "        else:\n",
    "            combined_df = new_df\n",
    "            new_count = len(new_df)\n",
    "        \n",
    "        # 保存到临时文件\n",
    "        combined_df.to_parquet(temp_path, engine='pyarrow', compression='snappy', index=False)\n",
    "        \n",
    "        # 验证临时文件\n",
    "        test_df = pd.read_parquet(temp_path)\n",
    "        assert len(test_df) == len(combined_df), \"临时文件验证失败\"\n",
    "        \n",
    "        # 备份原文件（如果存在）\n",
    "        if file_path.exists():\n",
    "            file_path.rename(backup_path)\n",
    "        \n",
    "        # 将临时文件重命名为正式文件\n",
    "        temp_path.rename(file_path)\n",
    "        \n",
    "        # 删除备份文件\n",
    "        if backup_path.exists():\n",
    "            backup_path.unlink()\n",
    "        \n",
    "        logger.info(f\"{symbol} 原子更新成功: 新增 {new_count} 条记录\")\n",
    "        return True, new_count\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"{symbol} 更新失败: {str(e)}\")\n",
    "        \n",
    "        # 回滚：恢复备份文件\n",
    "        if backup_path.exists() and not file_path.exists():\n",
    "            backup_path.rename(file_path)\n",
    "            logger.info(f\"{symbol} 已回滚到原数据\")\n",
    "        \n",
    "        # 清理临时文件\n",
    "        if temp_path.exists():\n",
    "            temp_path.unlink()\n",
    "        \n",
    "        return False, 0\n",
    "\n",
    "\n",
    "# 测试原子性更新\n",
    "if test_data:\n",
    "    print(\"\\n测试原子性更新:\")\n",
    "    for symbol in test_symbols[:1]:\n",
    "        success, new_count = atomic_update(symbol)\n",
    "        print(f\"{symbol}: {'成功' if success else '失败'}, 新增 {new_count} 条\")\n",
    "else:\n",
    "    print(\"\\n跳过原子性更新测试（无数据）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 18:59:17,625 - INFO - RB0 本地数据最后日期: 2025-08-18\n",
      "2025-08-18 18:59:17,627 - INFO - 正在获取 RB0 (螺纹钢) 的数据...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "测试批量更新并记录日志:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 18:59:17,993 - INFO - 成功获取 RB0 数据: 3982 条记录, 日期范围: 2009-03-27 至 2025-08-18\n",
      "2025-08-18 18:59:17,996 - INFO - RB0 无新数据\n",
      "2025-08-18 18:59:18,003 - INFO - 更新日志已记录: RB0 - success\n",
      "2025-08-18 18:59:18,006 - INFO - HC0 本地数据最后日期: 2025-08-18\n",
      "2025-08-18 18:59:18,006 - INFO - 正在获取 HC0 (热卷) 的数据...\n",
      "2025-08-18 18:59:18,304 - INFO - 成功获取 HC0 数据: 2780 条记录, 日期范围: 2014-03-21 至 2025-08-18\n",
      "2025-08-18 18:59:18,309 - INFO - HC0 无新数据\n",
      "2025-08-18 18:59:18,313 - INFO - 更新日志已记录: HC0 - success\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RB0: 成功, 新增 0 条\n",
      "HC0: 成功, 新增 0 条\n",
      "\n",
      "更新日志:\n",
      "                    timestamp symbol  new_records   status  error\n",
      "0  2025-08-18 18:59:17.997878    RB0            0  success    NaN\n",
      "1  2025-08-18 18:59:18.310076    HC0            0  success    NaN\n"
     ]
    }
   ],
   "source": [
    "# Cell name: log_update\n",
    "# Implements: REQ-DM.2.4\n",
    "\n",
    "def log_update(symbol: str, new_count: int, status: str, error_msg: str = \"\"):\n",
    "    \"\"\"\n",
    "    记录更新日志\n",
    "    \n",
    "    Args:\n",
    "        symbol: 品种代码\n",
    "        new_count: 新增记录数\n",
    "        status: 状态（success/failed）\n",
    "        error_msg: 错误信息（如果失败）\n",
    "    \"\"\"\n",
    "    log_entry = {\n",
    "        'timestamp': datetime.now(),\n",
    "        'symbol': symbol,\n",
    "        'new_records': new_count,\n",
    "        'status': status,\n",
    "        'error': error_msg\n",
    "    }\n",
    "    \n",
    "    # 读取现有日志（如果存在）\n",
    "    if Config.UPDATE_LOG_FILE.exists():\n",
    "        log_df = pd.read_csv(Config.UPDATE_LOG_FILE)\n",
    "    else:\n",
    "        log_df = pd.DataFrame()\n",
    "    \n",
    "    # 添加新日志\n",
    "    new_log_df = pd.DataFrame([log_entry])\n",
    "    log_df = pd.concat([log_df, new_log_df], ignore_index=True)\n",
    "    \n",
    "    # 保存日志\n",
    "    log_df.to_csv(Config.UPDATE_LOG_FILE, index=False)\n",
    "    logger.info(f\"更新日志已记录: {symbol} - {status}\")\n",
    "\n",
    "\n",
    "def batch_update_with_logging(symbols: List[str]) -> Dict[str, Tuple[bool, int]]:\n",
    "    \"\"\"\n",
    "    批量更新并记录日志\n",
    "    \n",
    "    Args:\n",
    "        symbols: 品种列表\n",
    "        \n",
    "    Returns:\n",
    "        更新结果字典\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        try:\n",
    "            success, new_count = atomic_update(symbol)\n",
    "            results[symbol] = (success, new_count)\n",
    "            \n",
    "            if success:\n",
    "                log_update(symbol, new_count, 'success')\n",
    "            else:\n",
    "                log_update(symbol, 0, 'failed', 'Update failed')\n",
    "                \n",
    "        except Exception as e:\n",
    "            results[symbol] = (False, 0)\n",
    "            log_update(symbol, 0, 'failed', str(e))\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# 测试批量更新\n",
    "if test_data:\n",
    "    print(\"\\n测试批量更新并记录日志:\")\n",
    "    update_results = batch_update_with_logging(test_symbols[:2])\n",
    "    for symbol, (success, new_count) in update_results.items():\n",
    "        print(f\"{symbol}: {'成功' if success else '失败'}, 新增 {new_count} 条\")\n",
    "    \n",
    "    # 显示更新日志\n",
    "    if Config.UPDATE_LOG_FILE.exists():\n",
    "        print(\"\\n更新日志:\")\n",
    "        log_df = pd.read_csv(Config.UPDATE_LOG_FILE)\n",
    "        print(log_df.tail())\n",
    "else:\n",
    "    print(\"\\n跳过批量更新测试（无数据）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Story DM.3: 统一数据访问\n",
    "\n",
    "### REQ-DM.3.1: 提供load_data统一接口\n",
    "### REQ-DM.3.2: 返回按日期索引对齐的宽表\n",
    "### REQ-DM.3.3: 自动前向填充缺失值\n",
    "### REQ-DM.3.4: 支持对数价格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 18:59:36,500 - INFO - 加载数据完成: 2 个品种, 242 条记录\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "测试统一数据加载接口:\n",
      "\n",
      "加载的数据形状: (242, 4)\n",
      "列名: ['RB0_close', 'RB0_volume', 'HC0_close', 'HC0_volume']\n",
      "\n",
      "数据前5行:\n",
      "            RB0_close  RB0_volume  HC0_close  HC0_volume\n",
      "date                                                    \n",
      "2023-01-03     4063.0     1245821     4099.0      343669\n",
      "2023-01-04     4027.0     1383006     4080.0      325413\n",
      "2023-01-05     4017.0     1522301     4073.0      384978\n",
      "2023-01-06     4107.0     1730447     4166.0      530367\n",
      "2023-01-09     4093.0     1607579     4146.0      430386\n"
     ]
    }
   ],
   "source": [
    "# Cell name: load_data\n",
    "# Implements: REQ-DM.3.1, REQ-DM.3.2\n",
    "\n",
    "def load_data(\n",
    "    symbols: List[str],\n",
    "    start_date: Optional[str] = None,\n",
    "    end_date: Optional[str] = None,\n",
    "    columns: List[str] = ['close'],\n",
    "    log_price: bool = False,\n",
    "    fill_method: str = 'ffill'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    统一的数据加载接口\n",
    "    \n",
    "    Args:\n",
    "        symbols: 品种列表\n",
    "        start_date: 开始日期 (YYYY-MM-DD)\n",
    "        end_date: 结束日期 (YYYY-MM-DD)\n",
    "        columns: 需要的数据列，默认['close']\n",
    "        log_price: 是否返回对数价格\n",
    "        fill_method: 缺失值填充方法 ('ffill', 'bfill', None)\n",
    "        \n",
    "    Returns:\n",
    "        按日期索引对齐的宽表DataFrame，列名格式: {symbol}_{column}\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        file_path = Config.FUTURES_DIR / f\"{symbol}.parquet\"\n",
    "        \n",
    "        if not file_path.exists():\n",
    "            raise FileNotFoundError(f\"{symbol} 数据文件不存在: {file_path}\")\n",
    "        \n",
    "        # 读取数据\n",
    "        df = pd.read_parquet(file_path)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.set_index('date')\n",
    "        \n",
    "        # 筛选日期范围\n",
    "        if start_date:\n",
    "            df = df[df.index >= pd.to_datetime(start_date)]\n",
    "        if end_date:\n",
    "            df = df[df.index <= pd.to_datetime(end_date)]\n",
    "        \n",
    "        # 选择需要的列\n",
    "        missing_cols = [col for col in columns if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"{symbol} 缺少列: {missing_cols}\")\n",
    "        \n",
    "        df = df[columns]\n",
    "        \n",
    "        # 重命名列\n",
    "        df.columns = [f\"{symbol}_{col}\" for col in columns]\n",
    "        \n",
    "        dfs.append(df)\n",
    "    \n",
    "    if not dfs:\n",
    "        raise ValueError(\"没有加载任何数据\")\n",
    "    \n",
    "    # 合并所有DataFrame（外连接，保留所有日期）\n",
    "    result = pd.concat(dfs, axis=1, join='outer')\n",
    "    \n",
    "    # 处理缺失值\n",
    "    if fill_method == 'ffill':\n",
    "        result = result.fillna(method='ffill')\n",
    "    elif fill_method == 'bfill':\n",
    "        result = result.fillna(method='bfill')\n",
    "    \n",
    "    # 应用对数变换\n",
    "    if log_price:\n",
    "        price_cols = [col for col in result.columns if any(p in col for p in ['open', 'high', 'low', 'close'])]\n",
    "        for col in price_cols:\n",
    "            if (result[col] <= 0).any():\n",
    "                raise ValueError(f\"{col} 包含非正数，无法进行对数变换\")\n",
    "            result[col] = np.log(result[col])\n",
    "    \n",
    "    # 按日期排序\n",
    "    result = result.sort_index()\n",
    "    \n",
    "    logger.info(f\"加载数据完成: {len(symbols)} 个品种, {len(result)} 条记录\")\n",
    "    return result\n",
    "\n",
    "\n",
    "# 测试数据加载\n",
    "if test_data and len(test_data) >= 2:\n",
    "    print(\"\\n测试统一数据加载接口:\")\n",
    "    try:\n",
    "        df = load_data(\n",
    "            symbols=list(test_data.keys())[:2],\n",
    "            start_date='2023-01-01',\n",
    "            end_date='2024-01-01',\n",
    "            columns=['close', 'volume']\n",
    "        )\n",
    "        print(f\"\\n加载的数据形状: {df.shape}\")\n",
    "        print(f\"列名: {list(df.columns)}\")\n",
    "        print(\"\\n数据前5行:\")\n",
    "        print(df.head())\n",
    "    except Exception as e:\n",
    "        print(f\"加载失败: {e}\")\n",
    "else:\n",
    "    print(\"\\n跳过数据加载测试（无足够数据）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 获取所有14个品种数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 18:59:56,041 - INFO - 正在获取 AG0 (白银) 的数据...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始获取所有14个品种数据...\n",
      "品种列表: ['AG0', 'AL0', 'AU0', 'CU0', 'HC0', 'I0', 'NI0', 'PB0', 'RB0', 'SF0', 'SM0', 'SN0', 'SS0', 'ZN0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 18:59:56,478 - INFO - 成功获取 AG0 数据: 3232 条记录, 日期范围: 2012-05-10 至 2025-08-18\n",
      "2025-08-18 18:59:57,488 - INFO - 正在获取 AL0 (铝) 的数据...\n",
      "2025-08-18 18:59:58,010 - INFO - 成功获取 AL0 数据: 5018 条记录, 日期范围: 2005-01-04 至 2025-08-18\n",
      "2025-08-18 18:59:59,017 - INFO - 正在获取 AU0 (黄金) 的数据...\n",
      "2025-08-18 18:59:59,315 - INFO - 成功获取 AU0 数据: 4291 条记录, 日期范围: 2008-01-09 至 2025-08-18\n",
      "2025-08-18 19:00:00,318 - INFO - 正在获取 CU0 (铜) 的数据...\n",
      "2025-08-18 19:00:00,641 - INFO - 成功获取 CU0 数据: 5018 条记录, 日期范围: 2005-01-04 至 2025-08-18\n",
      "2025-08-18 19:00:01,652 - INFO - 正在获取 HC0 (热卷) 的数据...\n",
      "2025-08-18 19:00:01,958 - INFO - 成功获取 HC0 数据: 2780 条记录, 日期范围: 2014-03-21 至 2025-08-18\n",
      "2025-08-18 19:00:02,969 - INFO - 正在获取 I0 (铁矿石) 的数据...\n",
      "2025-08-18 19:00:03,224 - INFO - 成功获取 I0 数据: 2879 条记录, 日期范围: 2013-10-18 至 2025-08-18\n",
      "2025-08-18 19:00:04,235 - INFO - 正在获取 NI0 (镍) 的数据...\n",
      "2025-08-18 19:00:04,514 - INFO - 成功获取 NI0 数据: 2530 条记录, 日期范围: 2015-03-27 至 2025-08-18\n",
      "2025-08-18 19:00:05,517 - INFO - 正在获取 PB0 (铅) 的数据...\n",
      "2025-08-18 19:00:05,778 - INFO - 成功获取 PB0 数据: 3501 条记录, 日期范围: 2011-03-24 至 2025-08-18\n",
      "2025-08-18 19:00:06,784 - INFO - 正在获取 RB0 (螺纹钢) 的数据...\n",
      "2025-08-18 19:00:07,089 - INFO - 成功获取 RB0 数据: 3982 条记录, 日期范围: 2009-03-27 至 2025-08-18\n",
      "2025-08-18 19:00:08,102 - INFO - 正在获取 SF0 (硅铁) 的数据...\n",
      "2025-08-18 19:00:08,267 - INFO - 成功获取 SF0 数据: 2649 条记录, 日期范围: 2014-08-12 至 2025-08-18\n",
      "2025-08-18 19:00:09,282 - INFO - 正在获取 SM0 (锰硅) 的数据...\n",
      "2025-08-18 19:00:09,560 - INFO - 成功获取 SM0 数据: 2632 条记录, 日期范围: 2014-08-12 至 2025-08-18\n",
      "2025-08-18 19:00:10,566 - INFO - 正在获取 SN0 (锡) 的数据...\n",
      "2025-08-18 19:00:10,824 - INFO - 成功获取 SN0 数据: 2530 条记录, 日期范围: 2015-03-27 至 2025-08-18\n",
      "2025-08-18 19:00:11,834 - INFO - 正在获取 SS0 (不锈钢) 的数据...\n",
      "2025-08-18 19:00:12,017 - INFO - 成功获取 SS0 数据: 1429 条记录, 日期范围: 2019-09-25 至 2025-08-18\n",
      "2025-08-18 19:00:13,033 - INFO - 正在获取 ZN0 (锌) 的数据...\n",
      "2025-08-18 19:00:13,399 - INFO - 成功获取 ZN0 数据: 4481 条记录, 日期范围: 2007-03-26 至 2025-08-18\n",
      "2025-08-18 19:00:14,402 - INFO - 批量获取完成: 成功 14/14 个品种\n",
      "2025-08-18 19:00:14,412 - INFO - 成功保存 AG0 数据到 ..\\data\\futures\\AG0.parquet\n",
      "2025-08-18 19:00:14,424 - INFO - 成功保存 AL0 数据到 ..\\data\\futures\\AL0.parquet\n",
      "2025-08-18 19:00:14,437 - INFO - 成功保存 AU0 数据到 ..\\data\\futures\\AU0.parquet\n",
      "2025-08-18 19:00:14,441 - INFO - 成功保存 CU0 数据到 ..\\data\\futures\\CU0.parquet\n",
      "2025-08-18 19:00:14,458 - INFO - 成功保存 HC0 数据到 ..\\data\\futures\\HC0.parquet\n",
      "2025-08-18 19:00:14,475 - INFO - 成功保存 I0 数据到 ..\\data\\futures\\I0.parquet\n",
      "2025-08-18 19:00:14,494 - INFO - 成功保存 NI0 数据到 ..\\data\\futures\\NI0.parquet\n",
      "2025-08-18 19:00:14,507 - INFO - 成功保存 PB0 数据到 ..\\data\\futures\\PB0.parquet\n",
      "2025-08-18 19:00:14,518 - INFO - 成功保存 RB0 数据到 ..\\data\\futures\\RB0.parquet\n",
      "2025-08-18 19:00:14,524 - INFO - 成功保存 SF0 数据到 ..\\data\\futures\\SF0.parquet\n",
      "2025-08-18 19:00:14,541 - INFO - 成功保存 SM0 数据到 ..\\data\\futures\\SM0.parquet\n",
      "2025-08-18 19:00:14,553 - INFO - 成功保存 SN0 数据到 ..\\data\\futures\\SN0.parquet\n",
      "2025-08-18 19:00:14,563 - INFO - 成功保存 SS0 数据到 ..\\data\\futures\\SS0.parquet\n",
      "2025-08-18 19:00:14,575 - INFO - 成功保存 ZN0 数据到 ..\\data\\futures\\ZN0.parquet\n",
      "2025-08-18 19:00:14,585 - INFO - 批量保存完成: 14/14 个文件\n",
      "2025-08-18 19:00:14,590 - INFO - 元信息已保存到 ..\\data\\metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "成功获取 14 个品种的数据\n",
      "\n",
      "成功保存 14 个文件\n",
      "\n",
      "元信息已更新\n"
     ]
    }
   ],
   "source": [
    "# 获取所有14个品种的数据\n",
    "print(\"开始获取所有14个品种数据...\")\n",
    "print(f\"品种列表: {Config.SYMBOLS}\")\n",
    "\n",
    "try:\n",
    "    all_data = fetch_multiple_symbols(Config.SYMBOLS)\n",
    "    print(f\"\\n成功获取 {len(all_data)} 个品种的数据\")\n",
    "    \n",
    "    # 保存所有数据\n",
    "    if all_data:\n",
    "        saved_files = batch_save_to_parquet(all_data)\n",
    "        print(f\"\\n成功保存 {len(saved_files)} 个文件\")\n",
    "        \n",
    "        # 更新元信息\n",
    "        save_metadata(all_data)\n",
    "        print(\"\\n元信息已更新\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n获取所有品种失败: {e}\")\n",
    "    all_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 数据质量检查和统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 数据统计报告 ===\n",
      "\n",
      "AG0 (白银):\n",
      "  记录数: 3232\n",
      "  日期范围: 2012-05-10 至 2025-08-18\n",
      "  最新收盘价: 9258.00\n",
      "  价格范围: 2937.00 - 9492.00\n",
      "\n",
      "AL0 (铝):\n",
      "  记录数: 5018\n",
      "  日期范围: 2005-01-04 至 2025-08-18\n",
      "  最新收盘价: 20595.00\n",
      "  价格范围: 9710.00 - 24695.00\n",
      "\n",
      "AU0 (黄金):\n",
      "  记录数: 4291\n",
      "  日期范围: 2008-01-09 至 2025-08-18\n",
      "  最新收盘价: 777.66\n",
      "  价格范围: 148.88 - 831.42\n",
      "\n",
      "CU0 (铜):\n",
      "  记录数: 5018\n",
      "  日期范围: 2005-01-04 至 2025-08-18\n",
      "  最新收盘价: 78950.00\n",
      "  价格范围: 22380.00 - 87670.00\n",
      "\n",
      "HC0 (热卷):\n",
      "  记录数: 2780\n",
      "  日期范围: 2014-03-21 至 2025-08-18\n",
      "  最新收盘价: 3419.00\n",
      "  价格范围: 1691.00 - 6683.00\n",
      "\n",
      "I0 (铁矿石):\n",
      "  记录数: 2879\n",
      "  日期范围: 2013-10-18 至 2025-08-18\n",
      "  最新收盘价: 772.00\n",
      "  价格范围: 284.00 - 1337.00\n",
      "\n",
      "NI0 (镍):\n",
      "  记录数: 2530\n",
      "  日期范围: 2015-03-27 至 2025-08-18\n",
      "  最新收盘价: 120460.00\n",
      "  价格范围: 64970.00 - 267700.00\n",
      "\n",
      "PB0 (铅):\n",
      "  记录数: 3501\n",
      "  日期范围: 2011-03-24 至 2025-08-18\n",
      "  最新收盘价: 16775.00\n",
      "  价格范围: 11770.00 - 21865.00\n",
      "\n",
      "RB0 (螺纹钢):\n",
      "  记录数: 3982\n",
      "  日期范围: 2009-03-27 至 2025-08-18\n",
      "  最新收盘价: 3155.00\n",
      "  价格范围: 1626.00 - 6171.00\n",
      "\n",
      "SF0 (硅铁):\n",
      "  记录数: 2649\n",
      "  日期范围: 2014-08-12 至 2025-08-18\n",
      "  最新收盘价: 5880.00\n",
      "  价格范围: 3408.00 - 17780.00\n",
      "\n",
      "SM0 (锰硅):\n",
      "  记录数: 2632\n",
      "  日期范围: 2014-08-12 至 2025-08-18\n",
      "  最新收盘价: 6120.00\n",
      "  价格范围: 3656.00 - 12890.00\n",
      "\n",
      "SN0 (锡):\n",
      "  记录数: 2530\n",
      "  日期范围: 2015-03-27 至 2025-08-18\n",
      "  最新收盘价: 267020.00\n",
      "  价格范围: 15905.00 - 391400.00\n",
      "\n",
      "SS0 (不锈钢):\n",
      "  记录数: 1429\n",
      "  日期范围: 2019-09-25 至 2025-08-18\n",
      "  最新收盘价: 13010.00\n",
      "  价格范围: 11800.00 - 22125.00\n",
      "\n",
      "ZN0 (锌):\n",
      "  记录数: 4481\n",
      "  日期范围: 2007-03-26 至 2025-08-18\n",
      "  最新收盘价: 22360.00\n",
      "  价格范围: 8650.00 - 34710.00\n"
     ]
    }
   ],
   "source": [
    "# 数据统计\n",
    "if all_data:\n",
    "    print(\"\\n=== 数据统计报告 ===\")\n",
    "    for symbol, df in all_data.items():\n",
    "        print(f\"\\n{symbol} ({Config.SYMBOL_NAMES[symbol]}):\")\n",
    "        print(f\"  记录数: {len(df)}\")\n",
    "        print(f\"  日期范围: {df['date'].min().date()} 至 {df['date'].max().date()}\")\n",
    "        print(f\"  最新收盘价: {df['close'].iloc[-1]:.2f}\")\n",
    "        print(f\"  价格范围: {df['close'].min():.2f} - {df['close'].max():.2f}\")\n",
    "else:\n",
    "    print(\"\\n没有数据可统计\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 总结\n",
    "\n",
    "### 已实现功能\n",
    "✅ **Story DM.1: 初始数据获取**\n",
    "- REQ-DM.1.1: 批量获取14个品种的0指数连续合约日线数据\n",
    "- REQ-DM.1.2: 数据字段包含必需字段\n",
    "- REQ-DM.1.3: 使用Parquet格式存储\n",
    "- REQ-DM.1.4: 记录元信息到metadata.json\n",
    "\n",
    "✅ **Story DM.2: 增量数据更新**\n",
    "- REQ-DM.2.1: 检测本地数据最后日期，仅获取新增数据\n",
    "- REQ-DM.2.2: 合并新旧数据，按日期去重\n",
    "- REQ-DM.2.3: 更新失败时回滚\n",
    "- REQ-DM.2.4: 生成更新日志\n",
    "\n",
    "✅ **Story DM.3: 统一数据访问**\n",
    "- REQ-DM.3.1: 提供load_data统一接口\n",
    "- REQ-DM.3.2: 返回按日期索引对齐的宽表\n",
    "- REQ-DM.3.3: 自动前向填充缺失值\n",
    "- REQ-DM.3.4: 支持对数价格\n",
    "\n",
    "### 注意事项\n",
    "- 所有数据均从AkShare实时获取，无任何mock或fallback\n",
    "- 如果AkShare API失败，程序将直接报错\n",
    "- 数据更新使用原子操作，确保数据完整性"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
