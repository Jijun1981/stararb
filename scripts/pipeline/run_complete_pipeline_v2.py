#!/usr/bin/env python3
"""
==============================================================================
                å®Œæ•´ç«¯åˆ°ç«¯é…å¯¹äº¤æ˜“ç®¡é“ v2.0 (åŸºäºåŸå­æœåŠ¡)
==============================================================================

ç‰ˆæœ¬æ›´æ–°è¯´æ˜ï¼š
- v2.0: å®Œå…¨åŸºäºåŸå­æœåŠ¡é‡æ„ï¼Œä½¿ç”¨BacktestEngineè¿›è¡Œå›æµ‹
- v1.0: åŸå§‹å®ç°ï¼ŒåŒ…å«è‡ªå®šä¹‰å›æµ‹é€»è¾‘

æ ¸å¿ƒåŸå­æœåŠ¡ï¼š
1. DataManager - æ•°æ®ç®¡ç†åŸå­æœåŠ¡
2. CointegrationAnalyzer - åæ•´åˆ†æåŸå­æœåŠ¡  
3. SignalGenerator - ä¿¡å·ç”ŸæˆåŸå­æœåŠ¡
4. BacktestEngine - å›æµ‹å¼•æ“åŸå­æœåŠ¡

==============================================================================
è¯¦ç»†ç®—æ³•æµç¨‹å’Œè®¡ç®—å‚æ•°ï¼š
==============================================================================

ç®—æ³•æµç¨‹è¯´æ˜ï¼š
1. åæ•´ç­›é€‰é˜¶æ®µ
   - ç­›é€‰91ä¸ªé…å¯¹ï¼ˆ14ä¸ªå“ç§çš„æ‰€æœ‰ç»„åˆï¼‰
   - ä½¿ç”¨5å¹´å’Œ1å¹´çš„på€¼éƒ½å°äº0.05ä½œä¸ºç­›é€‰æ¡ä»¶
   - ä½¿ç”¨æœ€è¿‘ä¸€å¹´(2024å¹´)çš„æ³¢åŠ¨ç‡ç¡®å®šæ–¹å‘ï¼ˆä½æ³¢åŠ¨ä½œXï¼Œé«˜æ³¢åŠ¨ä½œYï¼‰

2. Betaåˆå§‹åŒ–é˜¶æ®µ
   - ä½¿ç”¨2023å¹´å…¨å¹´æ•°æ®è®¡ç®—OLS betaä½œä¸ºåŸºç¡€Î²
   - è¿™ä¸ªOLS betaä½œä¸ºKalmanæ»¤æ³¢çš„åˆå§‹å€¼
   - è®¡ç®—2023å¹´æ®‹å·®æ–¹å·®ä½œä¸ºè§‚æµ‹å™ªå£°Rçš„åˆå§‹å€¼

3. Kalmané¢„çƒ­é˜¶æ®µï¼ˆæ”¶æ•›æœŸï¼‰
   - æ—¶é—´ï¼š2024å¹´1æœˆåˆ°6æœˆï¼ˆ6ä¸ªæœˆï¼‰
   - ç›®çš„ï¼šè®©Kalmanæ»¤æ³¢çš„betaæ”¶æ•›ç¨³å®š
   - è¿™æœŸé—´åªæ›´æ–°betaï¼Œä¸ç”Ÿæˆäº¤æ˜“ä¿¡å·
   - Betaæ—¥å˜åŒ–é™åˆ¶5%ï¼Œä½†æœ€å°ç»å¯¹å˜åŒ–0.001é˜²æ­¢æ­»èºæ—‹

4. ä¿¡å·ç”Ÿæˆé˜¶æ®µ
   - æ—¶é—´ï¼š2024å¹´7æœˆå¼€å§‹
   - ä½¿ç”¨æ”¶æ•›åçš„Kalmanæ»¤æ³¢åŠ¨æ€æ›´æ–°beta
   - Z-scoreé˜ˆå€¼ï¼š
     * å¼€ä»“ï¼š|Z| > 2.2
     * å¹³ä»“ï¼š|Z| < 0.3
   - æœ€å¤§æŒä»“30å¤©å¼ºåˆ¶å¹³ä»“

5. å›æµ‹é˜¶æ®µ
   - Betaçº¦æŸï¼šåªäº¤æ˜“[0.3, 3.0]èŒƒå›´å†…çš„ä¿¡å·
   - è´ŸBetaå¤„ç†ï¼š
     * æ­£Betaï¼ˆæ­£ç›¸å…³ï¼‰ï¼šä¼ ç»Ÿå¯¹å†²ï¼ˆä¹°Yå–X æˆ– å–Yä¹°Xï¼‰
     * è´ŸBetaï¼ˆè´Ÿç›¸å…³ï¼‰ï¼šåŒå‘æ“ä½œï¼ˆåŒæ—¶ä¹°æˆ–åŒæ—¶å–ï¼‰
   - ä¿è¯é‡‘ç‡ï¼š12%
   - æ­¢æŸï¼šä¿è¯é‡‘çš„15%
   - æ‰‹ç»­è´¹ï¼šä¸‡åˆ†ä¹‹2ï¼ˆåŒè¾¹ï¼‰
   - æ»‘ç‚¹ï¼š3ä¸ªtick

==============================================================================
å…·ä½“å‚æ•°é…ç½®ï¼š
==============================================================================

å“ç§é…ç½®ï¼š
- 14ä¸ªé‡‘å±æœŸè´§ï¼šAG0, AU0, AL0, CU0, NI0, PB0, SN0, ZN0, HC0, I0, RB0, SF0, SM0, SS0
- è´µé‡‘å±(2ä¸ª)ã€æœ‰è‰²é‡‘å±(6ä¸ª)ã€é»‘è‰²ç³»(6ä¸ª)

æ—¶é—´é…ç½®ï¼š
- Betaè®­ç»ƒæœŸï¼š2023-01-01 è‡³ 2023-12-31
- Kalmanæ”¶æ•›æœŸï¼š2024-01-01 è‡³ 2024-06-30
- ä¿¡å·ç”ŸæˆæœŸï¼š2024-07-01 è‡³ 2025-08-20

åæ•´ç­›é€‰å‚æ•°ï¼š
- 5å¹´æœŸpå€¼é˜ˆå€¼ï¼š< 0.05
- 1å¹´æœŸpå€¼é˜ˆå€¼ï¼š< 0.05  
- åŠè¡°æœŸçº¦æŸï¼š[2, 60]å¤©ï¼ˆä»…1å¹´æœŸï¼‰
- v2.0æ”¹è¿›ï¼šç§»é™¤5å¹´æœŸåŠè¡°æœŸçº¦æŸ

ä¿¡å·ç”Ÿæˆå‚æ•°ï¼š
- Z-scoreå¼€ä»“é˜ˆå€¼ï¼š> 2.2
- Z-scoreå¹³ä»“é˜ˆå€¼ï¼š< 0.3
- æ»šåŠ¨çª—å£ï¼š60ä¸ªäº¤æ˜“æ—¥
- æœ€å¤§æŒä»“ï¼š30å¤©å¼ºåˆ¶å¹³ä»“

Betaçº¦æŸå‚æ•°ï¼š
- Betaç»å¯¹å€¼èŒƒå›´ï¼š[0.3, 3.0]
- åªè¿‡æ»¤å¼€ä»“ä¿¡å·ï¼Œä¿ç•™æ‰€æœ‰å¹³ä»“ä¿¡å·

å›æµ‹äº¤æ˜“å‚æ•°ï¼š
- åˆå§‹èµ„é‡‘ï¼š500ä¸‡å…ƒ
- ä¿è¯é‡‘ç‡ï¼š12%
- æ‰‹ç»­è´¹ç‡ï¼šä¸‡åˆ†ä¹‹2ï¼ˆåŒè¾¹ï¼‰
- æ»‘ç‚¹è®¾ç½®ï¼šæ¯è…¿3ä¸ªtick
- æ­¢æŸå‚æ•°ï¼š15%ä¿è¯é‡‘æ­¢æŸï¼ˆå¯é…ç½®ï¼Œ1.0=100%ç¦ç”¨ï¼‰
- æ—¶é—´æ­¢æŸï¼š30å¤©æœ€å¤§æŒä»“

é£é™©æ§åˆ¶ï¼š
- è´ŸBetaå¤„ç†ï¼šæ­£Betaä¼ ç»Ÿå¯¹å†²ï¼Œè´ŸBetaåŒå‘æ“ä½œ
- ä¿è¯é‡‘ç®¡ç†ï¼šæŒ‰12%ä¿è¯é‡‘ç‡è®¡ç®—
- æ­¢æŸæœºåˆ¶ï¼šä¿è¯é‡‘çš„15%æŸå¤±è§¦å‘æ­¢æŸ
- å¼ºåˆ¶å¹³ä»“ï¼šæŒä»“30å¤©åå¼ºåˆ¶å¹³ä»“

==============================================================================

4. å›æµ‹æ‰§è¡Œé˜¶æ®µ (BacktestEngineåŸå­æœåŠ¡)
   äº¤æ˜“å‚æ•°ï¼š
   - åˆå§‹èµ„é‡‘: 500ä¸‡
   - ä¿è¯é‡‘ç‡: 12%
   - æ‰‹ç»­è´¹ç‡: ä¸‡åˆ†ä¹‹2 (åŒè¾¹)
   - æ»‘ç‚¹: æ¯è…¿3ä¸ªtick
   
   é£é™©æ§åˆ¶å‚æ•° (å¯é…ç½®):
   - æ­¢æŸæ¯”ä¾‹: å¯è®¾ç½® (15%å¯ç”¨æ­¢æŸï¼Œ100%ç¦ç”¨æ­¢æŸ)
   - æ—¶é—´æ­¢æŸ: 30å¤©
   
   æ‰‹æ•°è®¡ç®—ï¼š
   - ä¸‰ç§ç®—æ³•: ç½‘æ ¼æœç´¢ã€æ¯”ç‡çº¦ç®€ã€çº¿æ€§è§„åˆ’
   - ä½¿ç”¨Fractionç±»è®¡ç®—æœ€å°æ•´æ•°æ¯”
   - Y:Xæ‰‹æ•°æ¯”ä¾‹åŸºäºåŠ¨æ€Betaå€¼

5. ç»©æ•ˆåˆ†æé˜¶æ®µ
   è¾“å‡ºæŒ‡æ ‡ï¼š
   - åŸºç¡€ç»Ÿè®¡: æ€»äº¤æ˜“æ•°ã€èƒœç‡ã€ç›ˆäºæ¯”
   - æ”¶ç›ŠæŒ‡æ ‡: æ€»æ”¶ç›Šç‡ã€å¹´åŒ–æ”¶ç›Šç‡ã€å¤æ™®æ¯”ç‡ã€æœ€å¤§å›æ’¤
   - é£æ§ç»Ÿè®¡: æ­¢æŸæ¬¡æ•°ã€æ—¶é—´æ­¢æŸæ¬¡æ•°
   - äº¤æ˜“æ˜ç»†: æ¯ç¬”äº¤æ˜“çš„å®Œæ•´è®°å½•

==============================================================================

ä½œè€…: Claude Code
æ—¥æœŸ: 2025-08-21  
ç‰ˆæœ¬: v2.0
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import logging
import sys
from pathlib import Path

# æ·»åŠ libè·¯å¾„
sys.path.append('.')

# å¯¼å…¥æ‰€æœ‰åŸå­æœåŠ¡
from typing import Dict
from lib.data import DataManager, load_data
from lib.coint import CointegrationAnalyzer
from lib.signal_generation import SignalGenerator
from lib.backtest import BacktestEngine

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ==============================================================================
# å…¨å±€é…ç½®å‚æ•° v2.0
# ==============================================================================

# ç‰ˆæœ¬ä¿¡æ¯
PIPELINE_VERSION = "2.0"
PIPELINE_NAME = "å®Œæ•´ç«¯åˆ°ç«¯é…å¯¹äº¤æ˜“ç®¡é“"

# å“ç§åˆ—è¡¨ï¼ˆ14ä¸ªé‡‘å±æœŸè´§ï¼‰
SYMBOLS = [
    'AG0', 'AU0',  # è´µé‡‘å±
    'AL0', 'CU0', 'NI0', 'PB0', 'SN0', 'ZN0',  # æœ‰è‰²é‡‘å±
    'HC0', 'I0', 'RB0', 'SF0', 'SM0', 'SS0'  # é»‘è‰²ç³»
]

# æ—¶é—´é…ç½®
TIME_CONFIG = {
    'beta_training_start': '2023-01-01',
    'beta_training_end': '2023-12-31',
    'convergence_start': '2024-01-01', 
    'convergence_end': '2024-06-30',
    'signal_start': '2024-07-01',
    'backtest_end': '2025-08-20'
}

# åæ•´ç­›é€‰å‚æ•°
COINT_CONFIG = {
    'p_value_5y': 0.05,
    'p_value_1y': 0.05,
    'halflife_min': 2,
    'halflife_max': 60,
    'apply_5y_halflife_constraint': False  # v2.0ç§»é™¤5å¹´åŠè¡°æœŸçº¦æŸ
}

# ä¿¡å·ç”Ÿæˆå‚æ•°
SIGNAL_CONFIG = {
    'z_open': 2.2,
    'z_close': 0.3,
    'window': 60,
    'max_holding_days': 30
}

# Betaçº¦æŸå‚æ•°
BETA_CONFIG = {
    'min_abs': 0.3,
    'max_abs': 3.0
}

# å›æµ‹å‚æ•°
BACKTEST_CONFIG = {
    'initial_capital': 5000000,
    'margin_rate': 0.12,
    'commission_rate': 0.0002,
    'slippage_ticks': 3,
    'stop_loss_pct': 1.0,  # è®¾ç½®ä¸º1.0(100%)ç¦ç”¨æ­¢æŸï¼Œ0.15(15%)å¯ç”¨æ­¢æŸ
    'max_holding_days': 30
}

# åˆçº¦è§„æ ¼
CONTRACT_SPECS = {
    'AG0': {'multiplier': 15, 'tick_size': 1},
    'AU0': {'multiplier': 1000, 'tick_size': 0.02},
    'AL0': {'multiplier': 5, 'tick_size': 5},
    'CU0': {'multiplier': 5, 'tick_size': 10},
    'NI0': {'multiplier': 1, 'tick_size': 10},
    'PB0': {'multiplier': 5, 'tick_size': 5},
    'SN0': {'multiplier': 1, 'tick_size': 10},
    'ZN0': {'multiplier': 5, 'tick_size': 5},
    'HC0': {'multiplier': 10, 'tick_size': 1},
    'I0': {'multiplier': 100, 'tick_size': 0.5},
    'RB0': {'multiplier': 10, 'tick_size': 1},
    'SF0': {'multiplier': 5, 'tick_size': 2},
    'SM0': {'multiplier': 5, 'tick_size': 2},
    'SS0': {'multiplier': 5, 'tick_size': 5}
}

def print_header():
    """æ‰“å°ç®¡é“æ ‡é¢˜"""
    print("=" * 80)
    print(f"  {PIPELINE_NAME} v{PIPELINE_VERSION}")
    print("  åŸºäºåŸå­æœåŠ¡æ¶æ„")
    print("=" * 80)
    print(f"æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"å“ç§æ•°é‡: {len(SYMBOLS)}")
    print(f"é…å¯¹æ•°é‡: {len(SYMBOLS) * (len(SYMBOLS) - 1) // 2}")
    print(f"æ•°æ®èŒƒå›´: {TIME_CONFIG['beta_training_start']} ~ {TIME_CONFIG['backtest_end']}")
    print()

def step1_cointegration_screening(data_manager: DataManager) -> pd.DataFrame:
    """
    æ­¥éª¤1: åæ•´ç­›é€‰ (ä½¿ç”¨CointegrationAnalyzeråŸå­æœåŠ¡)
    
    Returns:
        ç¬¦åˆæ¡ä»¶çš„åæ•´é…å¯¹DataFrame
    """
    logger.info("=" * 60)
    logger.info("æ­¥éª¤1: åæ•´ç­›é€‰ (CointegrationAnalyzeråŸå­æœåŠ¡)")
    logger.info("=" * 60)
    
    # åˆå§‹åŒ–åæ•´åˆ†æå™¨
    data = load_data(SYMBOLS, 
                     start_date='2020-01-01',
                     columns=['close'], 
                     log_price=True)
    analyzer = CointegrationAnalyzer(data)
    
    # ç­›é€‰æ‰€æœ‰é…å¯¹
    logger.info("å¼€å§‹åæ•´ç­›é€‰...")
    significant_pairs = analyzer.screen_all_pairs(
        p_threshold=COINT_CONFIG['p_value_5y']
    )
    
    if len(significant_pairs) == 0:
        logger.error("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„åæ•´é…å¯¹!")
        return pd.DataFrame()
    
    logger.info(f"åæ•´ç­›é€‰å®Œæˆ:")
    logger.info(f"  æ€»é…å¯¹æ•°: {len(SYMBOLS) * (len(SYMBOLS) - 1) // 2}")
    logger.info(f"  é€šè¿‡ç­›é€‰: {len(significant_pairs)}")
    logger.info(f"  ç­›é€‰ç‡: {len(significant_pairs) / (len(SYMBOLS) * (len(SYMBOLS) - 1) // 2) * 100:.1f}%")
    
    # ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f'output/cointegrated_pairs_v2_{timestamp}.csv'
    significant_pairs.to_csv(output_file, index=False)
    logger.info(f"åæ•´ç»“æœä¿å­˜è‡³: {output_file}")
    
    return significant_pairs

def step2_signal_generation(pairs_df: pd.DataFrame, data_manager: DataManager) -> pd.DataFrame:
    """
    æ­¥éª¤2: ä¿¡å·ç”Ÿæˆ (ä½¿ç”¨SignalGeneratoråŸå­æœåŠ¡)
    
    Args:
        pairs_df: åæ•´é…å¯¹DataFrame
        data_manager: æ•°æ®ç®¡ç†å™¨
        
    Returns:
        äº¤æ˜“ä¿¡å·DataFrame
    """
    logger.info("=" * 60)
    logger.info("æ­¥éª¤2: ä¿¡å·ç”Ÿæˆ (SignalGeneratoråŸå­æœåŠ¡)")
    logger.info("=" * 60)
    
    # åˆå§‹åŒ–ä¿¡å·ç”Ÿæˆå™¨
    generator = SignalGenerator(
        z_open=SIGNAL_CONFIG['z_open'],
        z_close=SIGNAL_CONFIG['z_close'],
        window=SIGNAL_CONFIG['window']
    )
    
    # æ‰¹é‡ç”Ÿæˆæ‰€æœ‰é…å¯¹çš„ä¿¡å·
    logger.info("å¼€å§‹ä¿¡å·ç”Ÿæˆ...")
    
    # å‡†å¤‡å‚æ•°å­—å…¸
    pairs_params = {}
    for _, pair_row in pairs_df.iterrows():
        pair = pair_row['pair']
        pairs_params[pair] = {
            'beta_initial': pair_row.get('beta_5y', 1.0),
            'R': pair_row.get('residual_var_5y', 0.01)
        }
    
    # åŠ è½½ä»·æ ¼æ•°æ®
    price_data = load_data(SYMBOLS, 
                          start_date='2020-01-01',
                          columns=['close'], 
                          log_price=True)
    
    # SignalGeneratoréœ€è¦dateä½œä¸ºåˆ—è€Œä¸æ˜¯ç´¢å¼•
    if 'date' in price_data.index.names:
        price_data = price_data.reset_index()
    
    all_signals = generator.generate_all_signals(
        pairs_params=pairs_params,
        price_data=price_data,
        convergence_end=TIME_CONFIG['convergence_end'],
        signal_start=TIME_CONFIG['signal_start']
    )
    
    if len(all_signals) == 0:
        logger.error("æœªç”Ÿæˆä»»ä½•äº¤æ˜“ä¿¡å·!")
        return pd.DataFrame()
    
    logger.info(f"ä¿¡å·ç”Ÿæˆå®Œæˆ:")
    logger.info(f"  å¤„ç†é…å¯¹: {len(pairs_df)}")
    logger.info(f"  æ€»ä¿¡å·æ•°: {len(all_signals)}")
    
    # ç»Ÿè®¡ä¿¡å·ç±»å‹
    signal_counts = all_signals['signal'].value_counts()
    for signal_type, count in signal_counts.items():
        logger.info(f"  {signal_type}: {count}")
    
    # ä¿å­˜ä¿¡å·
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f'output/signals_v2_{timestamp}.csv'
    all_signals.to_csv(output_file, index=False)
    logger.info(f"ä¿¡å·ä¿å­˜è‡³: {output_file}")
    
    return all_signals

def step3_signal_filtering(signals_df: pd.DataFrame) -> pd.DataFrame:
    """
    æ­¥éª¤3: ä¿¡å·è¿‡æ»¤ (Betaçº¦æŸ)
    
    Args:
        signals_df: åŸå§‹ä¿¡å·DataFrame
        
    Returns:
        è¿‡æ»¤åçš„ä¿¡å·DataFrame
    """
    logger.info("=" * 60)
    logger.info("æ­¥éª¤3: ä¿¡å·è¿‡æ»¤ (Betaçº¦æŸ)")
    logger.info("=" * 60)
    
    original_count = len(signals_df)
    
    # åªè¿‡æ»¤å¼€ä»“ä¿¡å·
    open_signals = signals_df[signals_df['signal'].isin(['open_long', 'open_short'])].copy()
    close_signals = signals_df[signals_df['signal'] == 'close'].copy()
    
    # Betaçº¦æŸè¿‡æ»¤
    logger.info(f"åº”ç”¨Betaçº¦æŸ [{BETA_CONFIG['min_abs']}, {BETA_CONFIG['max_abs']}] (ç»å¯¹å€¼)")
    valid_mask = (abs(open_signals['beta']) >= BETA_CONFIG['min_abs']) & \
                 (abs(open_signals['beta']) <= BETA_CONFIG['max_abs'])
    
    filtered_count = (~valid_mask).sum()
    valid_open_signals = open_signals[valid_mask].copy()
    
    # åˆå¹¶æœ‰æ•ˆä¿¡å·
    filtered_signals = pd.concat([valid_open_signals, close_signals], ignore_index=True)
    filtered_signals = filtered_signals.sort_values('date').reset_index(drop=True)
    
    logger.info(f"ä¿¡å·è¿‡æ»¤å®Œæˆ:")
    logger.info(f"  åŸå§‹ä¿¡å·: {original_count}")
    logger.info(f"  è¿‡æ»¤å¼€ä»“ä¿¡å·: {filtered_count}")  
    logger.info(f"  æœ‰æ•ˆä¿¡å·: {len(filtered_signals)}")
    logger.info(f"  è¿‡æ»¤ç‡: {filtered_count / len(open_signals) * 100:.1f}%")
    
    return filtered_signals

def step4_backtest_execution(signals_df: pd.DataFrame, data_manager: DataManager) -> Dict:
    """
    æ­¥éª¤4: å›æµ‹æ‰§è¡Œ (ä½¿ç”¨BacktestEngineåŸå­æœåŠ¡)
    
    Args:
        signals_df: äº¤æ˜“ä¿¡å·DataFrame
        data_manager: æ•°æ®ç®¡ç†å™¨
        
    Returns:
        å›æµ‹ç»“æœå­—å…¸
    """
    logger.info("=" * 60) 
    logger.info("æ­¥éª¤4: å›æµ‹æ‰§è¡Œ (BacktestEngineåŸå­æœåŠ¡)")
    logger.info("=" * 60)
    
    # åˆå§‹åŒ–å›æµ‹å¼•æ“
    engine = BacktestEngine(
        initial_capital=BACKTEST_CONFIG['initial_capital'],
        margin_rate=BACKTEST_CONFIG['margin_rate'],
        commission_rate=BACKTEST_CONFIG['commission_rate'],
        slippage_ticks=BACKTEST_CONFIG['slippage_ticks'],
        stop_loss_pct=BACKTEST_CONFIG['stop_loss_pct'],
        max_holding_days=BACKTEST_CONFIG['max_holding_days']
    )
    
    # è®¾ç½®åˆçº¦è§„æ ¼
    engine.contract_specs = CONTRACT_SPECS
    
    # æ­¢æŸçŠ¶æ€åˆ¤æ–­
    stop_loss_enabled = BACKTEST_CONFIG['stop_loss_pct'] < 1.0
    stop_loss_desc = f"{BACKTEST_CONFIG['stop_loss_pct']*100:.0f}% ({'å¯ç”¨' if stop_loss_enabled else 'ç¦ç”¨'})"
    
    logger.info(f"å›æµ‹å¼•æ“é…ç½®:")
    logger.info(f"  åˆå§‹èµ„é‡‘: Â¥{BACKTEST_CONFIG['initial_capital']:,}")
    logger.info(f"  ä¿è¯é‡‘ç‡: {BACKTEST_CONFIG['margin_rate']*100:.0f}%")
    logger.info(f"  æ­¢æŸæ¯”ä¾‹: {stop_loss_desc}")
    logger.info(f"  æœ€å¤§æŒä»“: {BACKTEST_CONFIG['max_holding_days']}å¤©")
    logger.info(f"  ç‰ˆæœ¬æ¨¡å¼: {'æ— æ­¢æŸç‰ˆæœ¬(ä¸v1.0å¯¹æ¯”)' if not stop_loss_enabled else 'å®Œæ•´é£æ§ç‰ˆæœ¬'}")
    
    # å‡†å¤‡ä»·æ ¼æ•°æ®
    logger.info("åŠ è½½ä»·æ ¼æ•°æ®...")
    price_data = {}
    for symbol in SYMBOLS:
        df = data_manager.load_from_parquet(symbol)
        df['date'] = pd.to_datetime(df['date'])
        df.set_index('date', inplace=True)
        # ä½¿ç”¨ symbol_close æ ¼å¼ä½œä¸ºkeyï¼Œä¸ä¿¡å·é…å¯¹æ ¼å¼ä¿æŒä¸€è‡´
        price_data[f"{symbol}_close"] = df[['close']]
    
    # è½¬æ¢ä¿¡å·æ ¼å¼ä¸ºBacktestEngineéœ€è¦çš„æ ¼å¼
    logger.info("è½¬æ¢ä¿¡å·æ ¼å¼...")
    backtest_signals = []
    
    # å¤„ç†å¼€ä»“ä¿¡å·
    open_signals = signals_df[signals_df['signal'].isin(['open_long', 'open_short'])]
    for _, signal in open_signals.iterrows():
        pair = signal['pair']
        
        # åˆ¤æ–­ä¿¡å·ç±»å‹
        if signal['beta'] < 0:
            # è´ŸBetaï¼šåŒå‘æ“ä½œ
            signal_type = 'long_spread' if signal['signal'] == 'open_long' else 'short_spread'
        else:
            # æ­£Betaï¼šä¼ ç»Ÿå¯¹å†²
            signal_type = 'long_spread' if signal['signal'] == 'open_long' else 'short_spread'
        
        backtest_signals.append({
            'date': signal['date'],
            'pair': pair,
            'signal': signal_type,
            'theoretical_ratio': abs(signal['beta']),
            'z_score': signal.get('z_score', 0),
            'spread_formula': f"y - {abs(signal['beta']):.4f} * x"
        })
    
    # å¤„ç†å¹³ä»“ä¿¡å·
    close_signals = signals_df[signals_df['signal'] == 'close']
    for _, signal in close_signals.iterrows():
        backtest_signals.append({
            'date': signal['date'],
            'pair': signal['pair'],
            'signal': 'close',
            'z_score': signal.get('z_score', 0)
        })
    
    # æŒ‰æ—¥æœŸæ’åº
    backtest_signals = sorted(backtest_signals, key=lambda x: x['date'])
    logger.info(f"å¾…æ‰§è¡Œä¿¡å·: {len(backtest_signals)}")
    
    # æ‰§è¡Œå›æµ‹
    logger.info("å¼€å§‹å›æµ‹æ‰§è¡Œ...")
    
    # è·å–æ‰€æœ‰äº¤æ˜“æ—¥æœŸ
    all_dates = set()
    for signal in backtest_signals:
        all_dates.add(signal['date'])
    
    for symbol_data in price_data.values():
        all_dates.update(symbol_data.index)
    
    all_dates = sorted(all_dates)
    start_date = pd.Timestamp(TIME_CONFIG['signal_start'])
    end_date = pd.Timestamp(TIME_CONFIG['backtest_end'])
    all_dates = [d for d in all_dates if start_date <= d <= end_date]
    
    # æŒ‰æ—¥æœŸå¤„ç†ä¿¡å·
    signal_index = 0
    processed_signals = 0
    
    for current_date in all_dates:
        # è·å–å½“å‰ä»·æ ¼
        current_prices = {}
        for symbol, df in price_data.items():
            if current_date in df.index:
                current_prices[symbol] = df.loc[current_date, 'close']
        
        # æ‰§è¡Œé£é™©ç®¡ç†
        if current_prices:
            closed_pairs = engine.run_risk_management(current_date, current_prices)
            if closed_pairs:
                logger.debug(f"{current_date}: é£æ§å¹³ä»“ {len(closed_pairs)} ä¸ªé…å¯¹")
        
        # å¤„ç†å½“æ—¥ä¿¡å·
        while signal_index < len(backtest_signals):
            signal = backtest_signals[signal_index]
            if signal['date'] > current_date:
                break
            
            # æ‰§è¡Œä¿¡å·
            if current_prices:
                success = engine.execute_signal(signal, current_prices, current_date)
                if success:
                    processed_signals += 1
                    if processed_signals % 10 == 0:
                        logger.info(f"å·²å¤„ç†ä¿¡å·: {processed_signals}/{len(backtest_signals)}")
            
            signal_index += 1
        
        # æ—¥ç»ˆç»“ç®—
        if current_prices:
            engine.position_manager.daily_settlement(current_prices)
    
    logger.info(f"å›æµ‹æ‰§è¡Œå®Œæˆï¼Œå…±å¤„ç† {processed_signals} ä¸ªä¿¡å·")
    
    # ç”Ÿæˆå›æµ‹ç»“æœ
    results = engine.calculate_metrics()
    
    return results, engine

def step5_results_analysis(results: Dict, engine: BacktestEngine):
    """
    æ­¥éª¤5: ç»“æœåˆ†æå’Œè¾“å‡º
    
    Args:
        results: å›æµ‹ç»“æœå­—å…¸
        engine: å›æµ‹å¼•æ“å®ä¾‹
    """
    logger.info("=" * 60)
    logger.info("æ­¥éª¤5: ç»“æœåˆ†æ")
    logger.info("=" * 60)
    
    # åŸºç¡€ç»Ÿè®¡
    logger.info(f"ã€äº¤æ˜“ç»Ÿè®¡ã€‘")
    logger.info(f"  æ€»äº¤æ˜“æ•°: {results['total_trades']}")
    logger.info(f"  ç›ˆåˆ©äº¤æ˜“: {results['winning_trades']}")
    logger.info(f"  äºæŸäº¤æ˜“: {results['losing_trades']}")
    logger.info(f"  èƒœç‡: {results['win_rate']:.1f}%")
    
    # æ”¶ç›Šåˆ†æ
    logger.info(f"\nã€æ”¶ç›Šåˆ†æã€‘")
    logger.info(f"  æ€»å‡€ç›ˆäº: Â¥{results['total_pnl']:,.2f}")
    logger.info(f"  æ€»æ”¶ç›Šç‡: {results['total_return']:.2f}%")
    logger.info(f"  å¹´åŒ–æ”¶ç›Šç‡: {results.get('annual_return', 0):.2f}%")
    logger.info(f"  å¤æ™®æ¯”ç‡: {results.get('sharpe_ratio', 0):.2f}")
    logger.info(f"  æœ€å¤§å›æ’¤: {results.get('max_drawdown', 0):.2f}%")
    
    # é£æ§ç»Ÿè®¡
    stop_losses = sum(1 for r in engine.trade_records if r.get('close_reason') == 'stop_loss')
    time_stops = sum(1 for r in engine.trade_records if r.get('close_reason') == 'time_stop')
    
    logger.info(f"\nã€é£æ§ç»Ÿè®¡ã€‘")
    logger.info(f"  æ­¢æŸè§¦å‘: {stop_losses} æ¬¡")
    logger.info(f"  æ—¶é—´æ­¢æŸ: {time_stops} æ¬¡")
    logger.info(f"  æ­£å¸¸å¹³ä»“: {results['total_trades'] - stop_losses - time_stops} æ¬¡")
    
    # ä¿å­˜äº¤æ˜“è®°å½•
    if engine.trade_records:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        trades_df = pd.DataFrame(engine.trade_records)
        output_file = f'output/trades_v2_{timestamp}.csv'
        trades_df.to_csv(output_file, index=False)
        logger.info(f"\näº¤æ˜“è®°å½•ä¿å­˜è‡³: {output_file}")
        
        # åˆ†ææ­¢æŸäº¤æ˜“
        if stop_losses > 0:
            stop_loss_trades = trades_df[trades_df['close_reason'] == 'stop_loss']
            logger.info(f"\nã€æ­¢æŸäº¤æ˜“åˆ†æã€‘")
            avg_stop_loss = stop_loss_trades['net_pnl'].mean()
            logger.info(f"  å¹³å‡æ­¢æŸæŸå¤±: Â¥{avg_stop_loss:,.2f}")
            logger.info(f"  æ­¢æŸç‡: {stop_losses / results['total_trades'] * 100:.1f}%")
    
    # ç‰ˆæœ¬å¯¹æ¯”å’ŒéªŒç®—è¯´æ˜
    stop_loss_enabled = BACKTEST_CONFIG['stop_loss_pct'] < 1.0
    
    logger.info(f"\n" + "=" * 60)
    logger.info(f"  {PIPELINE_NAME} v{PIPELINE_VERSION} æ‰§è¡Œå®Œæˆ")
    logger.info("=" * 60)
    
    if not stop_loss_enabled:
        logger.info(f"ğŸ” éªŒç®—æ¨¡å¼ (ä¸v1.0å¯¹æ¯”):")
        logger.info(f"  - å½“å‰é…ç½®: æ­¢æŸ100%ç¦ç”¨ï¼Œåº”ä¸v1.0ç»“æœä¸€è‡´")
        logger.info(f"  - æ ¸å¿ƒæ”¹è¿›: ä½¿ç”¨BacktestEngineåŸå­æœåŠ¡")
        logger.info(f"  - è®¡ç®—ç²¾åº¦: åŒç®—æ³•éªŒè¯ï¼ŒFractionç±»æ‰‹æ•°è®¡ç®—")
        logger.info(f"  - ç§»é™¤çº¦æŸ: 5å¹´åŠè¡°æœŸçº¦æŸï¼Œæå‡ç­–ç•¥å®¹é‡")
        logger.info(f"  âš ï¸  å¦‚ç»“æœå·®å¼‚è¾ƒå¤§ï¼Œè¯·æ£€æŸ¥ç®—æ³•å®ç°")
    else:
        logger.info(f"ğŸ›¡ï¸  å®Œæ•´é£æ§æ¨¡å¼:")
        logger.info(f"  - æ­¢æŸæ§åˆ¶: {BACKTEST_CONFIG['stop_loss_pct']*100:.0f}%ä¿è¯é‡‘æ­¢æŸ")
        logger.info(f"  - æ—¶é—´æ§åˆ¶: {BACKTEST_CONFIG['max_holding_days']}å¤©æ—¶é—´æ­¢æŸ")  
        logger.info(f"  - é£é™©ä¼˜åŒ–: ç›¸æ¯”v1.0å¢åŠ å®Œæ•´é£é™©ç®¡ç†")
    
    logger.info(f"\nğŸ“ˆ v2.0æ ¸å¿ƒä¼˜åŠ¿:")
    logger.info(f"  âœ… 100%åŸå­æœåŠ¡æ¶æ„ï¼Œæ¨¡å—åŒ–ç¨‹åº¦æ›´é«˜")
    logger.info(f"  âœ… BacktestEngineä¸“ä¸šå›æµ‹ï¼ŒPnLè®¡ç®—æ›´ç²¾ç¡®")
    logger.info(f"  âœ… ä¸‰ç§æ‰‹æ•°ç®—æ³•ï¼ŒFractionç±»æœ€å°æ•´æ•°æ¯”")
    logger.info(f"  âœ… å¯é…ç½®æ­¢æŸå‚æ•°ï¼Œçµæ´»æ§åˆ¶é£é™©ç­–ç•¥")

def main():
    """
    ä¸»å‡½æ•° - å®Œæ•´ç«¯åˆ°ç«¯ç®¡é“æ‰§è¡Œ
    """
    try:
        # æ‰“å°æ ‡é¢˜
        print_header()
        
        # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
        logger.info("åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨...")
        data_manager = DataManager()
        
        # æ­¥éª¤1: åæ•´ç­›é€‰
        pairs_df = step1_cointegration_screening(data_manager)
        if len(pairs_df) == 0:
            logger.error("åæ•´ç­›é€‰å¤±è´¥ï¼Œç»ˆæ­¢æ‰§è¡Œ")
            return
        
        # æ­¥éª¤2: ä¿¡å·ç”Ÿæˆ
        signals_df = step2_signal_generation(pairs_df, data_manager)
        if len(signals_df) == 0:
            logger.error("ä¿¡å·ç”Ÿæˆå¤±è´¥ï¼Œç»ˆæ­¢æ‰§è¡Œ")
            return
        
        # æ­¥éª¤3: ä¿¡å·è¿‡æ»¤
        filtered_signals = step3_signal_filtering(signals_df)
        if len(filtered_signals) == 0:
            logger.error("æ‰€æœ‰ä¿¡å·è¢«è¿‡æ»¤ï¼Œç»ˆæ­¢æ‰§è¡Œ")
            return
        
        # æ­¥éª¤4: å›æµ‹æ‰§è¡Œ
        results, engine = step4_backtest_execution(filtered_signals, data_manager)
        if not results:
            logger.error("å›æµ‹æ‰§è¡Œå¤±è´¥ï¼Œç»ˆæ­¢æ‰§è¡Œ")
            return
        
        # æ­¥éª¤5: ç»“æœåˆ†æ
        step5_results_analysis(results, engine)
        
        logger.info(f"\nğŸ‰ ç®¡é“ v{PIPELINE_VERSION} æ‰§è¡Œå®Œæˆ!")
        
    except KeyboardInterrupt:
        logger.info("\nç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
    except Exception as e:
        logger.error(f"ç®¡é“æ‰§è¡Œå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()