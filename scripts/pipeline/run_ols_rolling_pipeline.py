#!/usr/bin/env python3
"""
OLSæ»šåŠ¨çª—å£å®Œæ•´Pipeline
ä¸Kalmanæ»¤æ³¢pipelineå¹¶è¡Œè¿è¡Œï¼Œè¿›è¡Œç­–ç•¥å¯¹æ¯”

=== è®¡ç®—æ¡ä»¶å’Œæ–¹æ³•è¯´æ˜ ===

1. æ•°æ®å‡†å¤‡æ¡ä»¶:
   - æ•°æ®èŒƒå›´: 2023-03-01è‡³ä»Š (æå‰4ä¸ªæœˆç¡®ä¿7æœˆ1æ—¥æœ‰è¶³å¤Ÿå†å²æ•°æ®)
   - æœ€å°æ•°æ®è¦æ±‚: æ¯ä¸ªé…å¯¹è‡³å°‘60å¤©æ•°æ®
   - æ•°æ®å¯¹é½: ä½¿ç”¨inner joinç¡®ä¿äº¤æ˜“æ—¥å¯¹é½
   - ä»·æ ¼è½¬æ¢: ä½¿ç”¨å¯¹æ•°ä»·æ ¼ log(price) è¿›è¡Œåæ•´å…³ç³»è®¡ç®—

2. OLSæ»šåŠ¨Betaè®¡ç®—æ–¹æ³•:
   - æ»šåŠ¨çª—å£: 60ä¸ªäº¤æ˜“æ—¥
   - å›å½’æ–¹ç¨‹æ ¹æ®direction:
     * x_on_y: log(price_x) = Î± + Î² * log(price_y) + Îµ
     * y_on_x: log(price_y) = Î± + Î² * log(price_x) + Îµ  
   - Betaè®¡ç®—: Î² = Cov(Y,X) / Var(X), å…¶ä¸­Yæ˜¯å› å˜é‡ï¼ŒXæ˜¯è‡ªå˜é‡
   - æ•°å€¼ç¨³å®šæ€§: è¦æ±‚æ ‡å‡†å·® > 1e-8, æ–¹å·® > 1e-8
   - è®¡ç®—é¢‘ç‡: æ¯ä¸ªäº¤æ˜“æ—¥æ›´æ–°ä¸€æ¬¡Betaå€¼

3. æ®‹å·®å’ŒZ-scoreè®¡ç®—:
   - æ®‹å·®è®¡ç®—: residual = Y_actual - Î² * X_actual
   - Z-scoreè®¡ç®—: Z = (å½“å‰æ®‹å·® - 60å¤©æ®‹å·®å‡å€¼) / 60å¤©æ®‹å·®æ ‡å‡†å·®
   - æ®‹å·®åºåˆ—: ä½¿ç”¨å½“å‰Betaé‡æ–°è®¡ç®—æ•´ä¸ª60å¤©çª—å£çš„æ®‹å·®
   - æ•°å€¼è¦æ±‚: æ®‹å·®æ ‡å‡†å·® > 1e-8

4. ä¿¡å·ç”Ÿæˆæ¡ä»¶:
   - ä¿¡å·å¼€å§‹: 2023å¹´7æœˆ1æ—¥ (ç¡®ä¿æœ‰è¶³å¤Ÿå†å²æ•°æ®è®­ç»ƒBeta)
   - å¼€ä»“æ¡ä»¶: |Z-score| > 2.0 ä¸” |Z-score| <= 3.2
   - å¹³ä»“æ¡ä»¶: |Z-score| < 0.5
   - å¼ºåˆ¶å¹³ä»“: æŒä»“30å¤©åå¼ºåˆ¶å¹³ä»“
   - æ­¢æŸæ¡ä»¶: æŸå¤±è¶…è¿‡ä¿è¯é‡‘çš„10%

5. å›æµ‹å‚æ•°è®¾ç½®:
   - åˆå§‹èµ„é‡‘: 500ä¸‡å…ƒäººæ°‘å¸
   - ä¿è¯é‡‘ç‡: 12% (æ‰€æœ‰å“ç§ç»Ÿä¸€)
   - äº¤æ˜“è´¹ç‡: ä¸‡åˆ†ä¹‹2 (åŒè¾¹)
   - æ»‘ç‚¹è®¾ç½®: æ¯è…¿3ä¸ªtick
   - ä»“ä½ç®¡ç†: æ¯é…å¯¹çº¦5%èµ„é‡‘åˆ†é…

Pipelineæ­¥éª¤:
1. åŠ è½½åæ•´é…å¯¹ç»“æœ (ä»shifted pipelineè¾“å‡º)
2. ä½¿ç”¨60å¤©æ»šåŠ¨OLSä¼°è®¡Beta
3. ç”ŸæˆZ-scoreäº¤æ˜“ä¿¡å· 
4. è¿è¡Œå›æµ‹åˆ†æ
5. ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š

ç¡®ä¿2023å¹´7æœˆ1æ—¥å¼€å§‹å°±æœ‰äº¤æ˜“ä¿¡å·
"""

import os
import sys
import json
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ libè·¯å¾„
sys.path.insert(0, '/mnt/e/Star-arb/lib')
sys.path.insert(0, '/mnt/e/Star-arb')

from lib.data import load_from_parquet, load_data
from lib.backtest import BacktestEngine, PositionManager

class OLSRollingPipeline:
    """OLSæ»šåŠ¨çª—å£Pipelineç±»"""
    
    def __init__(self, window=60, start_date='2023-07-01', end_date='2024-12-31'):
        self.window = window
        self.start_date = start_date  
        self.end_date = end_date
        self.data_start = '2023-03-01'  # æå‰4ä¸ªæœˆç¡®ä¿7æœˆ1æ—¥æœ‰è¶³å¤Ÿå†å²æ•°æ®
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_dir = f"/mnt/e/Star-arb/output/ols_rolling_{self.timestamp}"
        os.makedirs(self.output_dir, exist_ok=True)
        
        print(f"OLSæ»šåŠ¨Pipelineåˆå§‹åŒ–")
        print(f"æ»šåŠ¨çª—å£: {self.window}å¤©")
        print(f"ä¿¡å·æ—¥æœŸèŒƒå›´: {self.start_date} åˆ° {self.end_date}")
        print(f"è¾“å‡ºç›®å½•: {self.output_dir}")
    
    def load_cointegration_pairs(self):
        """åŠ è½½åæ•´é…å¯¹ç»“æœ"""
        coint_file = "/mnt/e/Star-arb/output/pipeline_shifted/cointegration_results.csv"
        
        if not os.path.exists(coint_file):
            raise FileNotFoundError(f"åæ•´ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {coint_file}")
            
        coint_results = pd.read_csv(coint_file)
        print(f"\nåŠ è½½åæ•´é…å¯¹: {len(coint_results)}ä¸ª")
        
        return coint_results
    
    def calculate_rolling_ols_beta(self, y_data, x_data, window=None):
        """
        è®¡ç®—æ»šåŠ¨OLS Beta
        
        Args:
            y_data: å› å˜é‡åºåˆ—
            x_data: è‡ªå˜é‡åºåˆ—  
            window: æ»šåŠ¨çª—å£å¤§å°
        
        Returns:
            pandas.Series: æ»šåŠ¨Betaåºåˆ—
        """
        if window is None:
            window = self.window
            
        aligned_data = pd.DataFrame({'y': y_data, 'x': x_data}).dropna()
        
        if len(aligned_data) < window:
            return pd.Series(dtype=float)
        
        beta_series = pd.Series(index=aligned_data.index, dtype=float)
        
        for i in range(window-1, len(aligned_data)):
            y_window = aligned_data['y'].iloc[i-window+1:i+1]
            x_window = aligned_data['x'].iloc[i-window+1:i+1]
            
            if len(y_window) == window and y_window.std() > 1e-8 and x_window.std() > 1e-8:
                # OLSå›å½’: y = alpha + beta * x
                covariance = np.cov(y_window, x_window, ddof=1)[0, 1]
                variance_x = np.var(x_window, ddof=1)
                
                if variance_x > 1e-8:
                    beta = covariance / variance_x
                    beta_series.iloc[i] = beta
        
        return beta_series
    
    def generate_pair_signals(self, pair_info):
        """
        ç”Ÿæˆå•ä¸ªé…å¯¹çš„ä¿¡å·
        
        Args:
            pair_info: dict, åŒ…å«é…å¯¹ä¿¡æ¯
            
        Returns:
            DataFrame: ä¿¡å·æ•°æ®
        """
        symbol_x = pair_info['symbol_x']
        symbol_y = pair_info['symbol_y']
        direction = pair_info['direction']
        
        try:
            # åŠ è½½æ•°æ®
            df_x = load_from_parquet(symbol_x)
            df_y = load_from_parquet(symbol_y)
            
            # ç­›é€‰æ—¥æœŸèŒƒå›´
            start_dt = pd.Timestamp(self.data_start)
            end_dt = pd.Timestamp(self.end_date)
            df_x = df_x[(df_x.index >= start_dt) & (df_x.index <= end_dt)]
            df_y = df_y[(df_y.index >= start_dt) & (df_y.index <= end_dt)]
            
            if df_x.empty or df_y.empty:
                print(f"  âŒ æ•°æ®ä¸ºç©º: {symbol_x}-{symbol_y}")
                return pd.DataFrame()
            
        except Exception as e:
            print(f"  âŒ æ•°æ®åŠ è½½å¤±è´¥: {symbol_x}-{symbol_y}, {e}")
            return pd.DataFrame()
        
        # åˆå¹¶æ•°æ®å¹¶å¯¹é½
        data = pd.merge(df_x[['close']], df_y[['close']], 
                       left_index=True, right_index=True, 
                       how='inner', suffixes=('_x', '_y'))
        
        if len(data) < self.window:
            print(f"  âŒ æ•°æ®ä¸è¶³{self.window}å¤©: {symbol_x}-{symbol_y}, åªæœ‰{len(data)}å¤©")
            return pd.DataFrame()
        
        # è®¡ç®—å¯¹æ•°ä»·æ ¼
        data['log_x'] = np.log(data['close_x'])
        data['log_y'] = np.log(data['close_y'])
        
        # æ ¹æ®æ–¹å‘ç¡®å®šå›å½’å…³ç³»
        if direction == 'x_on_y':
            # Xå¯¹Yå›å½’: log_x = alpha + beta * log_y
            y_var = data['log_x']  # å› å˜é‡
            x_var = data['log_y']  # è‡ªå˜é‡
        else:  # y_on_x
            # Yå¯¹Xå›å½’: log_y = alpha + beta * log_x
            y_var = data['log_y']  # å› å˜é‡  
            x_var = data['log_x']  # è‡ªå˜é‡
        
        # è®¡ç®—æ»šåŠ¨OLS Beta
        rolling_beta = self.calculate_rolling_ols_beta(y_var, x_var, self.window)
        
        if rolling_beta.empty:
            print(f"  âŒ Betaè®¡ç®—å¤±è´¥: {symbol_x}-{symbol_y}")
            return pd.DataFrame()
        
        # ç”Ÿæˆä¿¡å·
        signals = []
        
        for date in rolling_beta.dropna().index:
            if date < pd.Timestamp(self.start_date):
                continue
                
            beta = rolling_beta[date]
            if pd.isna(beta):
                continue
            
            # Betaçº¦æŸæ£€æŸ¥: ç»å¯¹å€¼å¿…é¡»åœ¨0.3-3ä¹‹é—´
            if abs(beta) < 0.3 or abs(beta) > 3.0:
                continue
                
            # è®¡ç®—å½“å‰æ®‹å·®
            current_residual = y_var[date] - beta * x_var[date]
            
            # è®¡ç®—æ»šåŠ¨çª—å£å†…çš„æ®‹å·®åºåˆ—ç”¨äºZ-scoreè®¡ç®—
            end_idx = data.index.get_loc(date)
            start_idx = max(0, end_idx - self.window + 1)
            window_data = data.iloc[start_idx:end_idx+1]
            
            # ä½¿ç”¨å½“å‰Betaè®¡ç®—çª—å£å†…æ‰€æœ‰æ®‹å·®
            if direction == 'x_on_y':
                residuals_window = window_data['log_x'] - beta * window_data['log_y']
            else:
                residuals_window = window_data['log_y'] - beta * window_data['log_x']
            
            if len(residuals_window) > 1 and residuals_window.std() > 1e-8:
                z_score = (current_residual - residuals_window.mean()) / residuals_window.std()
            else:
                continue
                
            signals.append({
                'date': date,
                'pair': f"{symbol_x}-{symbol_y}",
                'symbol_x': symbol_x,
                'symbol_y': symbol_y,
                'direction': direction,
                'price_x': data.loc[date, 'close_x'],
                'price_y': data.loc[date, 'close_y'],
                'ols_beta': beta,
                'residual': current_residual,
                'z_score': z_score
            })
        
        if not signals:
            print(f"  âŒ æœªç”Ÿæˆä¿¡å·: {symbol_x}-{symbol_y}")
            return pd.DataFrame()
            
        signals_df = pd.DataFrame(signals)
        signals_df.set_index('date', inplace=True)
        
        print(f"  âœ… {symbol_x}-{symbol_y}: {len(signals_df)}ä¸ªä¿¡å·, èŒƒå›´: {signals_df.index.min().strftime('%Y-%m-%d')} åˆ° {signals_df.index.max().strftime('%Y-%m-%d')}")
        
        return signals_df
    
    def generate_all_signals(self, coint_pairs):
        """ç”Ÿæˆæ‰€æœ‰é…å¯¹çš„ä¿¡å·"""
        print(f"\n{'='*60}")
        print("å¼€å§‹ç”ŸæˆOLSæ»šåŠ¨ä¿¡å·")
        print(f"{'='*60}")
        
        all_signals = []
        successful_pairs = 0
        
        for idx, row in coint_pairs.iterrows():
            pair_info = {
                'symbol_x': row['symbol_x'],
                'symbol_y': row['symbol_y'], 
                'direction': row['direction'],
                'pvalue_4y': row['pvalue_4y'],
                'beta_1y': row['beta_1y']
            }
            
            print(f"[{idx+1:2d}/{len(coint_pairs)}] å¤„ç†: {row['symbol_x']}-{row['symbol_y']} ({row['direction']})")
            
            signals_df = self.generate_pair_signals(pair_info)
            if not signals_df.empty:
                all_signals.append(signals_df)
                successful_pairs += 1
        
        print(f"\nä¿¡å·ç”Ÿæˆå®Œæˆ: {successful_pairs}/{len(coint_pairs)} é…å¯¹æˆåŠŸ")
        
        if not all_signals:
            raise ValueError("æœªç”Ÿæˆä»»ä½•ä¿¡å·")
            
        # åˆå¹¶æ‰€æœ‰ä¿¡å·
        combined_signals = pd.concat(all_signals, ignore_index=False)
        combined_signals.sort_index(inplace=True)
        
        return combined_signals
    
    def save_signals(self, signals_df):
        """ä¿å­˜ä¿¡å·æ•°æ®"""
        signals_file = f"{self.output_dir}/signals_ols_rolling_{self.timestamp}.csv"
        signals_df.to_csv(signals_file)
        
        print(f"\nä¿¡å·æ•°æ®ä¿å­˜: {signals_file}")
        print(f"æ€»ä¿¡å·æ•°: {len(signals_df)}")
        print(f"é…å¯¹æ•°: {signals_df['pair'].nunique()}")
        print(f"æ—¥æœŸèŒƒå›´: {signals_df.index.min()} åˆ° {signals_df.index.max()}")
        
        return signals_file
    
    def validate_signal_timing(self, signals_df):
        """éªŒè¯ä¿¡å·æ—¶é—´æ˜¯å¦ç¬¦åˆè¦æ±‚"""
        first_signal_date = signals_df.index.min()
        target_date = pd.Timestamp(self.start_date)
        
        print(f"\nä¿¡å·æ—¶é—´éªŒè¯:")
        print(f"ç›®æ ‡å¼€å§‹æ—¥æœŸ: {target_date.strftime('%Y-%m-%d')}")
        print(f"å®é™…é¦–ä¸ªä¿¡å·: {first_signal_date.strftime('%Y-%m-%d')}")
        
        # å…è®¸1å‘¨å†…çš„å·®å¼‚
        if first_signal_date <= target_date + timedelta(days=7):
            print("âœ… ä¿¡å·æ—¶é—´ç¬¦åˆè¦æ±‚")
            return True
        else:
            print("âŒ ä¿¡å·å¼€å§‹æ—¶é—´åæ™š")
            return False
    
    def run_backtest(self, signals_df):
        """è¿è¡Œå›æµ‹åˆ†æ"""
        print(f"\n{'='*60}")
        print("å¼€å§‹OLSæ»šåŠ¨ç­–ç•¥å›æµ‹")
        print(f"{'='*60}")
        
        try:
            # å›æµ‹å‚æ•°
            backtest_params = {
                'initial_capital': 5000000,
                'z_open_threshold': 2.5,
                'z_close_threshold': 0.5, 
                'z_open_max': 3.2,
                'stop_loss_pct': 0.15,  # 15%æ­¢æŸ
                'max_hold_days': 30
            }
            
            print("å›æµ‹å‚æ•°:")
            for key, value in backtest_params.items():
                print(f"  {key}: {value}")
            
            # åŠ è½½ä»·æ ¼æ•°æ®ç”¨äºå›æµ‹ (åŸå§‹ä»·æ ¼ï¼Œéå¯¹æ•°)
            print("\nåŠ è½½ä»·æ ¼æ•°æ®ç”¨äºå›æµ‹...")
            SYMBOLS = ['CU0', 'AL0', 'ZN0', 'NI0', 'SN0', 'PB0', 'AG0', 'AU0', 
                      'RB0', 'HC0', 'I0', 'SF0', 'SM0', 'SS0']
            
            price_data = load_data(
                symbols=SYMBOLS,
                start_date=self.start_date,
                end_date=self.end_date,
                columns=['close'],
                log_price=False  # å›æµ‹ä½¿ç”¨åŸå§‹ä»·æ ¼
            )
            
            # è·å–æ‰€æœ‰äº¤æ˜“æ—¥æœŸ
            all_dates = sorted(price_data.index.unique())
            start_date = pd.Timestamp(self.start_date)
            end_date = pd.Timestamp(self.end_date)
            trading_dates = [d for d in all_dates if start_date <= d <= end_date]
            
            # åˆå§‹åŒ–å›æµ‹å¼•æ“
            backtest_engine = BacktestEngine(
                initial_capital=backtest_params['initial_capital'],
                margin_rate=0.12,
                commission_rate=0.0002,
                slippage_ticks=3,
                stop_loss_pct=backtest_params['stop_loss_pct'],
                max_holding_days=backtest_params['max_hold_days']
            )
            
            # åŠ è½½åˆçº¦è§„æ ¼
            import json
            specs_file = "/mnt/e/Star-arb/configs/contract_specs.json"
            with open(specs_file, 'r', encoding='utf-8') as f:
                contract_specs = json.load(f)
            backtest_engine.contract_specs = contract_specs
            
            # è®¾ç½®ä»“ä½æƒé‡ï¼ˆæ¯é…å¯¹5%ï¼‰
            position_weights = {}
            for _, signal in signals_df.head(22).iterrows():  # å–22ä¸ªé…å¯¹
                pair = signal['pair']
                position_weights[pair] = 0.05
            backtest_engine.position_weights = position_weights
            
            # æŒ‰æ—¥æœŸåˆ†ç»„ä¿¡å·
            signals_by_date = {}
            for _, signal in signals_df.iterrows():
                signal_date = signal.name
                if signal_date not in signals_by_date:
                    signals_by_date[signal_date] = []
                
                # ç¡®å®šä¿¡å·ç±»å‹
                z = signal['z_score']
                if abs(z) >= backtest_params['z_open_threshold'] and abs(z) <= backtest_params['z_open_max']:
                    # å¼€ä»“ä¿¡å·
                    if z > 0:
                        signal_type = 'open_short'  # Z-score > 0, åšç©ºä»·å·®
                    else:
                        signal_type = 'open_long'   # Z-score < 0, åšå¤šä»·å·®
                elif abs(z) <= backtest_params['z_close_threshold']:
                    signal_type = 'close'
                else:
                    signal_type = None  # æ— ä¿¡å·
                
                if signal_type is None:
                    continue
                
                # è½¬æ¢ä¸ºä¿¡å·å­—å…¸æ ¼å¼
                signal_dict = {
                    'pair': signal['pair'],
                    'signal': signal_type,
                    'date': signal_date,  # æ·»åŠ dateå­—æ®µ
                    'symbol_x': signal['symbol_x'],
                    'symbol_y': signal['symbol_y'],
                    'direction': signal['direction'],
                    'beta': signal['ols_beta'],  # ä½¿ç”¨OLS beta
                    'theoretical_ratio': abs(signal['ols_beta']),  # æ‰‹æ•°è®¡ç®—éœ€è¦çš„ç†è®ºæ¯”ç‡
                    'z_score': signal['z_score'],
                    'price_x': signal['price_x'],
                    'price_y': signal['price_y'],
                    'ols_beta': signal['ols_beta']  # é¢å¤–è®°å½•OLS beta
                }
                signals_by_date[signal_date].append(signal_dict)
            
            print(f"å›æµ‹æ—¥æœŸèŒƒå›´: {start_date} è‡³ {end_date}")
            print(f"æ€»äº¤æ˜“æ—¥æ•°: {len(trading_dates)}")
            print(f"æœ‰ä¿¡å·æ—¥æ•°: {len(signals_by_date)}")
            
            # æ‰§è¡Œæ¯æ—¥å›æµ‹
            processed_signals = 0
            for i, current_date in enumerate(trading_dates):
                if i % 50 == 0:
                    print(f"  å¤„ç†è¿›åº¦: {i+1}/{len(trading_dates)} ({current_date.strftime('%Y-%m-%d')})")
                    
                # è·å–å½“å‰ä»·æ ¼
                current_prices = {}
                for symbol in SYMBOLS:
                    col_name = f"{symbol}_close"
                    if col_name in price_data.columns:
                        current_prices[symbol] = price_data.loc[current_date, col_name]
                
                # å¤„ç†å½“æ—¥ä¿¡å·
                if current_date in signals_by_date:
                    for signal in signals_by_date[current_date]:
                        if backtest_engine.execute_signal(signal, current_prices, current_date):
                            processed_signals += 1
                
                # é£é™©ç®¡ç† - æ£€æŸ¥å¹¶æ‰§è¡Œæ­¢æŸç­‰é£é™©æ§åˆ¶
                force_close_list = backtest_engine.run_risk_management(current_date, current_prices)
                
                # æ‰§è¡Œå¼ºåˆ¶å¹³ä»“
                for item in force_close_list:
                    pair = item['pair']
                    reason = item['reason']
                    backtest_engine._close_position(pair, current_prices, reason, current_date)
            
            print(f"å¤„ç†ä¿¡å·æ€»æ•°: {processed_signals}")
            
            # ç”Ÿæˆå›æµ‹ç»“æœ
            performance_summary = backtest_engine.generate_performance_summary()
            
            # è·å–äº¤æ˜“è®°å½•å’Œå…¶ä»–æ•°æ®
            results = {
                'summary': performance_summary,
                'trades': backtest_engine.trade_records,
                'positions': backtest_engine.position_manager.positions,
                'daily_pnl': getattr(backtest_engine, 'daily_pnl', {}),
                'capital_history': getattr(backtest_engine, 'equity_curve', [])
            }
            
            # ä¿å­˜ç»“æœæ–‡ä»¶
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # ä¿å­˜äº¤æ˜“è®°å½•
            if results.get('trades'):
                trades_file = f"{self.output_dir}/trades_{timestamp}.csv"
                trades_df = pd.DataFrame(results['trades'])
                trades_df.to_csv(trades_file, index=False)
                print(f"\näº¤æ˜“è®°å½•ä¿å­˜: {trades_file}")
            
            # ä¿å­˜å›æµ‹æŠ¥å‘Š
            report_file = f"{self.output_dir}/backtest_report_{timestamp}.json"
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            print(f"å›æµ‹æŠ¥å‘Šä¿å­˜: {report_file}")
            
            return results
            
        except Exception as e:
            print(f"âŒ å›æµ‹è¿è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def generate_summary_report(self, backtest_result):
        """ç”Ÿæˆç­–ç•¥æ€»ç»“æŠ¥å‘Š"""
        if not backtest_result or 'summary' not in backtest_result:
            print("âŒ æ— æ³•ç”ŸæˆæŠ¥å‘Šï¼Œå›æµ‹ç»“æœç¼ºå¤±")
            return
            
        summary = backtest_result['summary']
        
        print(f"\n{'='*60}")
        print("OLSæ»šåŠ¨ç­–ç•¥å›æµ‹ç»“æœ")
        print(f"{'='*60}")
        
        key_metrics = [
            ('æ€»æ”¶ç›Šç‡', 'total_return', '.2%'),
            ('å¹´åŒ–æ”¶ç›Šç‡', 'annualized_return', '.2%'),
            ('å¤æ™®æ¯”ç‡', 'sharpe_ratio', '.3f'),
            ('æœ€å¤§å›æ’¤', 'max_drawdown', '.2%'),
            ('æ€»äº¤æ˜“æ¬¡æ•°', 'total_trades', 'd'),
            ('èƒœç‡', 'win_rate', '.1%'),
            ('å¹³å‡æŒä»“å¤©æ•°', 'avg_hold_days', '.1f'),
            ('ç›ˆäºæ¯”', 'profit_loss_ratio', '.2f')
        ]
        
        for name, key, fmt in key_metrics:
            value = summary.get(key, 'N/A')
            if value != 'N/A':
                if fmt.endswith('%'):
                    print(f"{name:12}: {value:{fmt}}")
                elif fmt.endswith('f'):
                    print(f"{name:12}: {value:{fmt}}")
                else:
                    print(f"{name:12}: {value}")
            else:
                print(f"{name:12}: {value}")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_data = {
            'pipeline_type': 'OLS_Rolling',
            'window_size': self.window,
            'signal_period': f"{self.start_date} to {self.end_date}",
            'timestamp': self.timestamp,
            'summary': summary,
            'parameters': {
                'z_open_threshold': 2.5,
                'z_close_threshold': 0.5,
                'z_open_max': 3.2,
                'stop_loss_pct': 0.15,  # 15%æ­¢æŸ
                'max_hold_days': 30,
                'initial_capital': 5000000
            }
        }
        
        report_file = f"{self.output_dir}/backtest_report_{self.timestamp}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2, default=str)
            
        print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
    def run_complete_pipeline(self):
        """è¿è¡Œå®Œæ•´pipelineæµç¨‹"""
        print(f"{'='*80}")
        print("OLSæ»šåŠ¨çª—å£å®Œæ•´Pipelineå¯åŠ¨")
        print(f"{'='*80}")
        
        try:
            # 1. åŠ è½½åæ•´é…å¯¹
            coint_pairs = self.load_cointegration_pairs()
            
            # 2. ç”Ÿæˆä¿¡å·
            signals_df = self.generate_all_signals(coint_pairs)
            
            # 3. ä¿å­˜ä¿¡å·
            signals_file = self.save_signals(signals_df)
            
            # 4. éªŒè¯ä¿¡å·æ—¶é—´
            self.validate_signal_timing(signals_df)
            
            # 5. è¿è¡Œå›æµ‹
            backtest_result = self.run_backtest(signals_df)
            
            # 6. ç”ŸæˆæŠ¥å‘Š
            if backtest_result:
                self.generate_summary_report(backtest_result)
                
            print(f"\n{'='*80}")
            print("OLSæ»šåŠ¨Pipelineå®Œæˆ!")
            print(f"è¾“å‡ºç›®å½•: {self.output_dir}")
            print(f"{'='*80}")
            
            return {
                'signals_file': signals_file,
                'backtest_result': backtest_result,
                'output_dir': self.output_dir
            }
            
        except Exception as e:
            print(f"âŒ Pipelineè¿è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºå¹¶è¿è¡ŒOLSæ»šåŠ¨Pipeline
    pipeline = OLSRollingPipeline(
        window=60,
        start_date='2023-07-01',
        end_date='2024-12-31'
    )
    
    result = pipeline.run_complete_pipeline()
    
    if result:
        print("\nğŸ‰ PipelineæˆåŠŸå®Œæˆ!")
        print(f"æŸ¥çœ‹ç»“æœ: {result['output_dir']}")
    else:
        print("\nâŒ Pipelineæ‰§è¡Œå¤±è´¥")
        sys.exit(1)

if __name__ == "__main__":
    main()