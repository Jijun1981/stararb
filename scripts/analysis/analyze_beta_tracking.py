#!/usr/bin/env python3
"""
æ ¸å¿ƒé—®é¢˜åˆ†æï¼šé¢„çƒ­æœŸÎ²å˜å¼‚å’ŒKalman vs OLSæ»šåŠ¨Î²å¯¹æ¯”
"""
import pandas as pd
import numpy as np
from lib.data import load_all_symbols_data
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
from scipy.stats import pearsonr
import os

def calculate_rolling_ols_beta(x_data, y_data, window=60):
    """è®¡ç®—æ»šåŠ¨OLS Î²å€¼"""
    betas = []
    for i in range(window, len(x_data)):
        x_window = x_data[i-window:i]
        y_window = y_data[i-window:i]
        
        reg = LinearRegression(fit_intercept=False)  # ä¸Kalmanä¸€è‡´ï¼šæ— æˆªè·
        reg.fit(x_window.reshape(-1, 1), y_window)
        betas.append(reg.coef_[0])
    
    return np.array(betas)

def analyze_beta_tracking():
    """åˆ†æÎ²å€¼è·Ÿè¸ªæ•ˆæœ"""
    
    print("ğŸ” æ ¸å¿ƒé—®é¢˜åˆ†æï¼šKalman vs OLSæ»šåŠ¨Î²å¯¹æ¯”")
    print("=" * 60)
    
    # 1. åŠ è½½æ•°æ®å’Œæœ€æ–°ä¿¡å·
    data = load_all_symbols_data()
    
    signal_files = [f for f in os.listdir('.') if f.startswith('signals_e2e_') and f.endswith('.csv')]
    if not signal_files:
        print("âŒ æœªæ‰¾åˆ°ä¿¡å·æ–‡ä»¶")
        return
        
    latest_signal_file = max(signal_files)
    signals_df = pd.read_csv(latest_signal_file)
    signals_df['date'] = pd.to_datetime(signals_df['date'])
    
    print(f"åˆ†æä¿¡å·æ–‡ä»¶: {latest_signal_file}")
    
    # 2. é€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§é…å¯¹è¿›è¡Œè¯¦ç»†åˆ†æ
    analysis_pairs = ['NI-AG', 'AU-ZN', 'CU-SN', 'RB-SM', 'ZN-SM']
    
    results = {}
    
    for pair in analysis_pairs:
        if pair not in signals_df['pair'].unique():
            print(f"âš ï¸ è·³è¿‡{pair}ï¼šæ•°æ®ä¸­ä¸å­˜åœ¨")
            continue
            
        print(f"\n=== {pair}é…å¯¹åˆ†æ ===")
        
        # è·å–è¯¥é…å¯¹çš„ä¿¡å·æ•°æ®
        pair_signals = signals_df[signals_df['pair'] == pair].copy()
        pair_signals = pair_signals.sort_values('date')
        
        # è·å–ç¬¦å·
        symbol_x = pair_signals['symbol_x'].iloc[0]
        symbol_y = pair_signals['symbol_y'].iloc[0]
        
        print(f"é…å¯¹: {symbol_x} -> {symbol_y}")
        
        # è·å–åŸå§‹ä»·æ ¼æ•°æ®ï¼ˆä¿¡å·ç”ŸæˆæœŸï¼‰
        signal_start_date = pair_signals['date'].min()
        signal_end_date = pair_signals['date'].max()
        
        price_data_period = data[signal_start_date:signal_end_date]
        
        if symbol_x not in price_data_period.columns or symbol_y not in price_data_period.columns:
            print(f"âŒ ä»·æ ¼æ•°æ®ä¸å®Œæ•´")
            continue
            
        # å¯¹é½ä»·æ ¼æ•°æ®
        x_prices = price_data_period[symbol_x].dropna()
        y_prices = price_data_period[symbol_y].dropna()
        common_dates = x_prices.index.intersection(y_prices.index)
        
        x_aligned = x_prices[common_dates].values
        y_aligned = y_prices[common_dates].values
        dates_aligned = common_dates
        
        print(f"ä»·æ ¼æ•°æ®ç‚¹æ•°: {len(x_aligned)}")
        
        # 3. è®¡ç®—æ»šåŠ¨60å¤©OLS Î²
        rolling_betas = calculate_rolling_ols_beta(x_aligned, y_aligned, window=60)
        rolling_dates = dates_aligned[60:]  # å¯¹åº”æ»šåŠ¨Î²çš„æ—¥æœŸ
        
        print(f"æ»šåŠ¨OLS Î²èŒƒå›´: [{rolling_betas.min():.6f}, {rolling_betas.max():.6f}]")
        print(f"æ»šåŠ¨OLS Î²æ ‡å‡†å·®: {np.std(rolling_betas):.6f}")
        
        # 4. å¯¹é½Kalman Î²å€¼
        # åŒ¹é…æ—¥æœŸ
        kalman_betas = []
        kalman_dates_matched = []
        ols_betas_matched = []
        
        for i, date in enumerate(rolling_dates):
            # æ‰¾åˆ°æœ€æ¥è¿‘çš„Kalmanä¿¡å·æ—¥æœŸ
            signal_on_date = pair_signals[pair_signals['date'] == date]
            if len(signal_on_date) > 0:
                kalman_beta = signal_on_date['beta'].iloc[0]
                kalman_betas.append(kalman_beta)
                kalman_dates_matched.append(date)
                ols_betas_matched.append(rolling_betas[i])
        
        if len(kalman_betas) < 10:
            print(f"âŒ åŒ¹é…çš„æ•°æ®ç‚¹å¤ªå°‘: {len(kalman_betas)}")
            continue
            
        kalman_betas = np.array(kalman_betas)
        ols_betas_matched = np.array(ols_betas_matched)
        
        print(f"åŒ¹é…æ•°æ®ç‚¹æ•°: {len(kalman_betas)}")
        
        # 5. å…³é”®åˆ†æï¼šç›¸å…³æ€§
        correlation, p_value = pearsonr(kalman_betas, ols_betas_matched)
        
        print(f"ğŸ¯ Kalman vs OLSç›¸å…³æ€§: {correlation:.4f} (p={p_value:.4e})")
        
        # 6. åå·®åˆ†æ
        beta_diff = kalman_betas - ols_betas_matched
        mean_diff = np.mean(beta_diff)
        std_diff = np.std(beta_diff)
        max_diff = np.max(np.abs(beta_diff))
        
        print(f"å¹³å‡åå·®: {mean_diff:.6f}")
        print(f"åå·®æ ‡å‡†å·®: {std_diff:.6f}")
        print(f"æœ€å¤§ç»å¯¹åå·®: {max_diff:.6f}")
        
        # 7. é¢„çƒ­æœŸÎ²å˜å¼‚åˆ†æ
        beta_initial = pair_signals['beta_initial'].iloc[0]
        
        # é¢„çƒ­æœŸç»“æŸåçš„ç¬¬ä¸€ä¸ªÎ²å€¼ï¼ˆåº”è¯¥æ¥è¿‘OLSé¢„çƒ­å€¼ï¼‰
        warmup_signals = pair_signals[pair_signals['phase'] == 'warm_up']
        signal_period_signals = pair_signals[pair_signals['phase'] == 'signal_period']
        
        if len(warmup_signals) > 0 and len(signal_period_signals) > 0:
            beta_after_warmup = signal_period_signals['beta'].iloc[0]
            
            print(f"Î²åˆå§‹å€¼(åæ•´): {beta_initial:.6f}")
            print(f"é¢„çƒ­ç»“æŸåÎ²å€¼: {beta_after_warmup:.6f}")
            print(f"é¢„çƒ­æœŸÎ²å˜åŒ–: {abs(beta_after_warmup - beta_initial):.6f}")
            
            # ç†è®ºä¸Šé¢„çƒ­ç»“æŸåçš„Î²åº”è¯¥æ¥è¿‘OLSé¢„çƒ­æœŸçš„Î²
            # è®¡ç®—é¢„çƒ­æœŸçš„ç†è®ºOLS Î²
            if len(x_aligned) >= 60:
                x_warmup = x_aligned[:60] - np.mean(x_aligned[:60])  # å»ä¸­å¿ƒåŒ–
                y_warmup = y_aligned[:60] - np.mean(y_aligned[:60])
                
                reg_warmup = LinearRegression(fit_intercept=False)
                reg_warmup.fit(x_warmup.reshape(-1, 1), y_warmup)
                theoretical_warmup_beta = reg_warmup.coef_[0]
                
                print(f"ç†è®ºOLSé¢„çƒ­Î²: {theoretical_warmup_beta:.6f}")
                print(f"å®é™…vsç†è®ºé¢„çƒ­å·®å¼‚: {abs(beta_after_warmup - theoretical_warmup_beta):.6f}")
        
        # 8. è·Ÿè¸ªè´¨é‡è¯„ä¼°
        if correlation > 0.8:
            tracking_quality = "ä¼˜ç§€"
        elif correlation > 0.6:
            tracking_quality = "è‰¯å¥½"
        elif correlation > 0.4:
            tracking_quality = "ä¸€èˆ¬"
        else:
            tracking_quality = "å·®"
            
        print(f"ğŸ“Š è·Ÿè¸ªè´¨é‡: {tracking_quality}")
        
        # ä¿å­˜ç»“æœ
        results[pair] = {
            'correlation': correlation,
            'p_value': p_value,
            'mean_diff': mean_diff,
            'std_diff': std_diff,
            'max_diff': max_diff,
            'tracking_quality': tracking_quality,
            'n_points': len(kalman_betas),
            'beta_initial': beta_initial,
            'beta_range_kalman': [kalman_betas.min(), kalman_betas.max()],
            'beta_range_ols': [ols_betas_matched.min(), ols_betas_matched.max()],
            'kalman_betas': kalman_betas,
            'ols_betas': ols_betas_matched,
            'dates': kalman_dates_matched
        }
    
    # 9. æ€»ä½“åˆ†æ
    print(f"\n=== æ€»ä½“åˆ†æç»“æœ ===")
    
    if results:
        correlations = [r['correlation'] for r in results.values()]
        mean_correlations = np.mean(correlations)
        
        print(f"å¹³å‡ç›¸å…³æ€§: {mean_correlations:.4f}")
        print(f"ç›¸å…³æ€§èŒƒå›´: [{min(correlations):.4f}, {max(correlations):.4f}]")
        
        # è´¨é‡åˆ†å¸ƒ
        qualities = [r['tracking_quality'] for r in results.values()]
        from collections import Counter
        quality_count = Counter(qualities)
        
        print(f"è·Ÿè¸ªè´¨é‡åˆ†å¸ƒ:")
        for quality, count in quality_count.items():
            print(f"  {quality}: {count}ä¸ªé…å¯¹")
        
        # æ‰¾å‡ºé—®é¢˜é…å¯¹
        problem_pairs = [pair for pair, result in results.items() if result['correlation'] < 0.6]
        if problem_pairs:
            print(f"\nâš ï¸ éœ€è¦å…³æ³¨çš„é…å¯¹ (ç›¸å…³æ€§<0.6):")
            for pair in problem_pairs:
                r = results[pair]
                print(f"  {pair}: ç›¸å…³æ€§={r['correlation']:.4f}, æœ€å¤§åå·®={r['max_diff']:.4f}")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        summary_data = []
        for pair, result in results.items():
            summary_data.append({
                'pair': pair,
                'correlation': result['correlation'],
                'p_value': result['p_value'],
                'mean_diff': result['mean_diff'],
                'std_diff': result['std_diff'],
                'max_diff': result['max_diff'],
                'tracking_quality': result['tracking_quality'],
                'n_points': result['n_points'],
                'beta_initial': result['beta_initial'],
                'kalman_beta_min': result['beta_range_kalman'][0],
                'kalman_beta_max': result['beta_range_kalman'][1],
                'ols_beta_min': result['beta_range_ols'][0],
                'ols_beta_max': result['beta_range_ols'][1]
            })
        
        summary_df = pd.DataFrame(summary_data)
        output_file = f"kalman_ols_beta_comparison_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv"
        summary_df.to_csv(output_file, index=False)
        print(f"\nğŸ“Š è¯¦ç»†åˆ†æç»“æœå·²ä¿å­˜: {output_file}")
        
        # 10. å…³é”®ç»“è®º
        print(f"\nğŸ¯ å…³é”®ç»“è®º:")
        
        if mean_correlations > 0.8:
            print("âœ… Kalmanæ»¤æ³¢å™¨æ•´ä½“è·Ÿè¸ªæ•ˆæœä¼˜ç§€ï¼ŒÎ²å€¼å˜å¼‚åˆç†")
        elif mean_correlations > 0.6:
            print("âœ… Kalmanæ»¤æ³¢å™¨æ•´ä½“è·Ÿè¸ªæ•ˆæœè‰¯å¥½ï¼Œå¯æ¥å—èŒƒå›´å†…")
        elif mean_correlations > 0.4:
            print("âš ï¸ Kalmanæ»¤æ³¢å™¨è·Ÿè¸ªæ•ˆæœä¸€èˆ¬ï¼Œéœ€è¦å‚æ•°è°ƒä¼˜")
        else:
            print("âŒ Kalmanæ»¤æ³¢å™¨è·Ÿè¸ªæ•ˆæœå·®ï¼Œå­˜åœ¨ç³»ç»Ÿæ€§é—®é¢˜")
            
        if len(problem_pairs) > 0:
            print(f"âš ï¸ {len(problem_pairs)}ä¸ªé…å¯¹éœ€è¦ç‰¹åˆ«å…³æ³¨")
        
        return results, summary_df
    else:
        print("âŒ æ— æ³•å®Œæˆåˆ†æï¼Œæ•°æ®ä¸è¶³")
        return None, None

if __name__ == "__main__":
    results, summary = analyze_beta_tracking()