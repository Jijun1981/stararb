#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Kalmanæ»¤æ³¢å‚æ•°ç½‘æ ¼æœç´¢
ç›®æ ‡ï¼šæ‰¾åˆ°æœ€ä½³å‚æ•°ç»„åˆ
- æ®‹å·®å¹³ç¨³æ€§æœ€å¤§åŒ–
- |z|>=2æ¯”ä¾‹åœ¨2%-5%ä¹‹é—´
"""

import pandas as pd
import numpy as np
import sys
import os
from datetime import datetime
import logging
from statsmodels.tsa.stattools import adfuller

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from lib.data import load_all_symbols_data
from lib.coint import CointegrationAnalyzer
from lib.signal_generation import AdaptiveSignalGenerator

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.WARNING)  # å‡å°‘æ—¥å¿—è¾“å‡º


def adf_test_simple(residuals):
    """ç®€åŒ–çš„ADFæ£€éªŒ"""
    try:
        clean_residuals = residuals.dropna()
        if len(clean_residuals) < 20:
            return False
        result = adfuller(clean_residuals, autolag='AIC')
        return result[1] < 0.05  # på€¼<0.05ä¸ºå¹³ç¨³
    except:
        return False


def test_mean_reversion(signal_data, price_data):
    """æµ‹è¯•|z|>2æ—¶çš„å‡å€¼å›å½’æ”¶ç›Š"""
    returns = []
    
    for pair in signal_data['pair'].unique():
        pair_signals = signal_data[signal_data['pair'] == pair].copy()
        
        # åªçœ‹|z|>2çš„ç‚¹
        extreme_signals = pair_signals[pair_signals['z_score'].abs() > 2].copy()
        
        if len(extreme_signals) < 3:
            continue
            
        symbol_x = pair_signals['symbol_x'].iloc[0]
        symbol_y = pair_signals['symbol_y'].iloc[0]
        
        # è·å–ä»·æ ¼æ•°æ®
        if symbol_x not in price_data.columns or symbol_y not in price_data.columns:
            continue
            
        for _, row in extreme_signals.iterrows():
            date = row['date']
            z_score = row['z_score']
            beta = row['beta']
            
            # æ‰¾åˆ°åç»­5å¤©çš„æ•°æ®
            try:
                date_idx = price_data.index.get_loc(pd.to_datetime(date))
                if date_idx + 5 >= len(price_data):
                    continue
                    
                # Tæ—¥å’ŒT+5æ—¥ä»·æ ¼
                x_t0 = price_data[symbol_x].iloc[date_idx]
                y_t0 = price_data[symbol_y].iloc[date_idx]  
                x_t5 = price_data[symbol_x].iloc[date_idx + 5]
                y_t5 = price_data[symbol_y].iloc[date_idx + 5]
                
                # è®¡ç®—spreadå˜åŒ–
                spread_t0 = y_t0 - beta * x_t0
                spread_t5 = y_t5 - beta * x_t5
                spread_change = spread_t5 - spread_t0
                
                # å‡å€¼å›å½’é¢„æœŸï¼šz_scoreä¸spread_changeåº”è¯¥åå‘
                # å¦‚æœz>2ï¼ˆspreadè¿‡é«˜ï¼‰ï¼Œé¢„æœŸspread_change<0ï¼ˆå›å½’ï¼‰
                # å¦‚æœz<-2ï¼ˆspreadè¿‡ä½ï¼‰ï¼Œé¢„æœŸspread_change>0ï¼ˆå›å½’ï¼‰
                expected_return = -np.sign(z_score) * spread_change
                returns.append(expected_return)
                
            except:
                continue
    
    if len(returns) < 5:
        return 0, 0
        
    mean_return = np.mean(returns)
    ir = mean_return / (np.std(returns) + 1e-8)  # ä¿¡æ¯æ¯”ç‡
    
    return mean_return, ir


def evaluate_params(delta_init, p0_scale, delta_min, lambda_r, test_pairs, price_data):
    """è¯„ä¼°ä¸€ç»„å‚æ•°çš„æ•ˆæœ"""
    
    # ä¿®æ”¹AdaptiveKalmanFilterçš„å‚æ•°
    from lib.signal_generation import AdaptiveKalmanFilter
    
    # ä¸´æ—¶ä¿å­˜åŸå§‹å‚æ•°
    original_warm_up = AdaptiveKalmanFilter.warm_up_ols
    
    def new_warm_up_ols(self, x_data, y_data, window=60):
        # å»ä¸­å¿ƒåŒ–å¤„ç†
        self.mu_x = np.mean(x_data[:window])
        self.mu_y = np.mean(y_data[:window])
        x_use = x_data[:window] - self.mu_x
        y_use = y_data[:window] - self.mu_y
        
        # OLSå›å½’
        from sklearn.linear_model import LinearRegression
        reg = LinearRegression(fit_intercept=False)
        reg.fit(x_use.reshape(-1, 1), y_use)
        
        self.beta = float(reg.coef_[0])
        innovations = y_use - reg.predict(x_use.reshape(-1, 1)).flatten()
        self.R = float(np.var(innovations, ddof=1))
        
        # è°ƒæ•´P0åˆå§‹åŒ–
        x_var = np.var(x_use, ddof=1)
        self.P = p0_scale * self.R / max(x_var, 1e-12)  # ä½¿ç”¨å‚æ•°åŒ–çš„P0
        
        return {
            'beta': self.beta, 'R': self.R, 'P': self.P,
            'mu_x': self.mu_x, 'mu_y': self.mu_y
        }
    
    # ä¸´æ—¶æ›¿æ¢æ–¹æ³•
    AdaptiveKalmanFilter.warm_up_ols = new_warm_up_ols
    
    try:
        # åˆ›å»ºä¿¡å·ç”Ÿæˆå™¨ (ä½¿ç”¨å‚æ•°åŒ–çš„deltaå’Œlambda)
        sg = AdaptiveSignalGenerator(
            z_open=2.0, z_close=0.5, max_holding_days=30, calibration_freq=5,
            ols_window=60, warm_up_days=30
        )
        
        # ä¸´æ—¶ä¿®æ”¹deltaå‚æ•°
        sg._delta_init = delta_init
        sg._delta_min = delta_min  
        sg._lambda_r = lambda_r
        
        # å¤„ç†æµ‹è¯•é…å¯¹
        results = sg.process_all_pairs(
            pairs_df=test_pairs,
            price_data=price_data,
            beta_window='1y'
        )
        
        if results.empty:
            return None
            
        # åˆ†æç»“æœ
        signal_period = results[results['phase'] == 'signal_period']
        
        # 1. Z-scoreåˆ†å¸ƒ
        z_scores = signal_period['z_score']
        z_over2_pct = (z_scores.abs() >= 2).mean() * 100
        z_std = z_scores.std()
        
        # 2. æ®‹å·®å¹³ç¨³æ€§æµ‹è¯•
        stationarity_scores = []
        
        for pair in test_pairs['pair']:
            pair_data = signal_period[signal_period['pair'] == pair]
            if len(pair_data) > 50:  # è¶³å¤Ÿçš„æ•°æ®ç‚¹
                innovations = pair_data['innovation'].values
                is_stationary = adf_test_simple(pd.Series(innovations))
                stationarity_scores.append(is_stationary)
        
        stationarity_rate = np.mean(stationarity_scores) * 100 if stationarity_scores else 0
        
        # 3. å‡å€¼å›å½’æ”¶ç›Šæµ‹è¯• (å…³é”®æ–°å¢!)
        mean_reversion_return, mean_reversion_ir = test_mean_reversion(signal_period, price_data)
        
        # 4. è´¨é‡è¯„ä¼°
        quality_report = sg.get_quality_report()
        good_quality_pct = (quality_report['quality_status'] == 'good').mean() * 100
        
        # 5. ç»¼åˆè¯„åˆ† (æ–°å¢å‡å€¼å›å½’æƒé‡)
        z_score_bonus = 15 if 2 <= z_over2_pct <= 5 else 0
        mr_bonus = 10 if mean_reversion_return > 0 else 0  # å‡å€¼å›å½’æ”¶ç›Š>0å¥–åŠ±
        ir_bonus = 5 if mean_reversion_ir > 0.2 else 0     # IR>0.2é¢å¤–å¥–åŠ±
        
        total_score = stationarity_rate + z_score_bonus + mr_bonus + ir_bonus
        
        return {
            'delta_init': delta_init,
            'p0_scale': p0_scale, 
            'delta_min': delta_min,
            'lambda_r': lambda_r,
            'z_over2_pct': z_over2_pct,
            'z_std': z_std,
            'stationarity_rate': stationarity_rate,
            'mean_reversion_return': mean_reversion_return,
            'mean_reversion_ir': mean_reversion_ir,
            'good_quality_pct': good_quality_pct,
            'n_pairs': len(stationarity_scores),
            'score': total_score  # ç»¼åˆè¯„åˆ†
        }
        
    except Exception as e:
        print(f"å‚æ•°ç»„åˆå¤±è´¥: delta_init={delta_init}, p0_scale={p0_scale}, error={e}")
        return None
    finally:
        # æ¢å¤åŸå§‹æ–¹æ³•
        AdaptiveKalmanFilter.warm_up_ols = original_warm_up
        

def main():
    print("=" * 80)
    print("Kalmanæ»¤æ³¢å‚æ•°ç½‘æ ¼æœç´¢")
    print("ç›®æ ‡: æ®‹å·®å¹³ç¨³æ€§ + |z|>=2åœ¨2%-5%")
    print("=" * 80)
    
    # 1. åŠ è½½æ•°æ®
    print("åŠ è½½æ•°æ®...")
    price_data = load_all_symbols_data()
    analysis_data = price_data['2024-04-01':'2025-08-24'].copy()
    
    # 2. é€‰æ‹©ä»£è¡¨æ€§é…å¯¹ï¼ˆå¿«é€Ÿæµ‹è¯•ç”¨ï¼‰
    test_pairs = pd.DataFrame({
        'pair': ['CU-SN', 'HC-SM', 'ZN-SM', 'RB-SM', 'SS-NI', 'SM-I'],
        'symbol_x': ['CU', 'HC', 'ZN', 'RB', 'SS', 'SM'], 
        'symbol_y': ['SN', 'SM', 'SM', 'SM', 'NI', 'I'],
        'beta_1y': [0.977974, 0.920247, 0.684857, 1.046174, 0.829148, 0.682580]
    })
    
    print(f"æµ‹è¯•é…å¯¹: {list(test_pairs['pair'])}")
    
    # 3. å®šä¹‰æœç´¢ç½‘æ ¼ - ç®€å•ä½†å…³é”®çš„å‚æ•°
    param_grid = {
        'delta_init': [0.96, 0.98, 0.99],           # åˆå§‹delta  
        'p0_scale': [1.0, 3.0, 5.0],               # P0ç¼©æ”¾å› å­
        'delta_min': [0.90, 0.93, 0.95],           # deltaä¸‹ç•Œ
        'lambda_r': [0.92, 0.96, 0.98]             # Rçš„EWMAå‚æ•°
    }
    
    print(f"æœç´¢ç©ºé—´: {len(param_grid['delta_init']) * len(param_grid['p0_scale']) * len(param_grid['delta_min']) * len(param_grid['lambda_r'])}ä¸ªç»„åˆ")
    
    # 4. ç½‘æ ¼æœç´¢
    results = []
    total_combinations = len(param_grid['delta_init']) * len(param_grid['p0_scale']) * len(param_grid['delta_min']) * len(param_grid['lambda_r'])
    current = 0
    
    for delta_init in param_grid['delta_init']:
        for p0_scale in param_grid['p0_scale']:
            for delta_min in param_grid['delta_min']:
                for lambda_r in param_grid['lambda_r']:
                    current += 1
                    print(f"\nè¿›åº¦ {current}/{total_combinations}: delta_init={delta_init}, p0_scale={p0_scale}, delta_min={delta_min}, lambda_r={lambda_r}")
                    
                    result = evaluate_params(
                        delta_init, p0_scale, delta_min, lambda_r,
                        test_pairs, analysis_data
                    )
                    
                    if result:
                        results.append(result)
                        print(f"  |z|>=2: {result['z_over2_pct']:.2f}%, å¹³ç¨³æ€§: {result['stationarity_rate']:.1f}%, "
                              f"MRæ”¶ç›Š: {result['mean_reversion_return']:.4f}, IR: {result['mean_reversion_ir']:.2f}, è¯„åˆ†: {result['score']:.1f}")
    
    # 5. åˆ†æç»“æœ
    if results:
        results_df = pd.DataFrame(results)
        
        print("\n" + "=" * 80)
        print("ç½‘æ ¼æœç´¢ç»“æœ")
        print("=" * 80)
        
        # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
        top_results = results_df.nlargest(10, 'score')
        
        print("\næœ€ä½³å‚æ•°ç»„åˆ (å‰10å):")
        print("-" * 140)
        for i, (_, row) in enumerate(top_results.iterrows(), 1):
            print(f"{i:2d}. delta_init={row['delta_init']:.2f}, p0_scale={row['p0_scale']:.1f}, "
                  f"delta_min={row['delta_min']:.2f}, lambda_r={row['lambda_r']:.2f}")
            print(f"     |z|>=2: {row['z_over2_pct']:.2f}%, å¹³ç¨³æ€§: {row['stationarity_rate']:.1f}%, "
                  f"MRæ”¶ç›Š: {row['mean_reversion_return']:.4f}, IR: {row['mean_reversion_ir']:.2f}, è¯„åˆ†: {row['score']:.1f}")
            print()
        
        # ä¿å­˜ç»“æœ
        output_file = f"kalman_grid_search_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        results_df.to_csv(output_file, index=False)
        print(f"è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        # æ¨èæœ€ä½³å‚æ•°
        best = top_results.iloc[0]
        print(f"\nğŸ¯ æ¨èå‚æ•°:")
        print(f"   delta_init = {best['delta_init']}")
        print(f"   p0_scale = {best['p0_scale']}")
        print(f"   delta_min = {best['delta_min']}")  
        print(f"   lambda_r = {best['lambda_r']}")
        print(f"   é¢„æœŸæ•ˆæœ: |z|>=2çº¦{best['z_over2_pct']:.1f}%, å¹³ç¨³æ€§çº¦{best['stationarity_rate']:.1f}%")
        print(f"   å‡å€¼å›å½’: æ”¶ç›Š{best['mean_reversion_return']:.4f}, IR={best['mean_reversion_ir']:.2f}")
    else:
        print("æœªè·å¾—æœ‰æ•ˆç»“æœ")
    
    print("\n" + "=" * 80)
    print("æœç´¢å®Œæˆ")
    print("=" * 80)


if __name__ == "__main__":
    main()