#!/usr/bin/env python3
"""
åˆ†ææ ·æœ¬å¤–Z>2ä¿¡å·çš„å›å½’æ”¶ç›Š
éªŒè¯ï¼šZ>2ä¿¡å· â†’ å›å½’åæ”¶ç›Š > 0
"""
import pandas as pd
import numpy as np
import sys
sys.path.append('.')

from lib.data import load_all_symbols_data
from sklearn.linear_model import LinearRegression
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

def analyze_regression_returns():
    """åˆ†ææ ·æœ¬å¤–Z>2ä¿¡å·çš„å›å½’æ”¶ç›Š"""
    
    print("ğŸ“Š æ ·æœ¬å¤–Z>2ä¿¡å·å›å½’æ”¶ç›Šåˆ†æ")
    print("=" * 70)
    
    # åŠ è½½æœ€æ–°çš„ä¼˜åŒ–å‚æ•°ä¿¡å·
    try:
        # æ‰¾åˆ°æœ€æ–°çš„ä¿¡å·æ–‡ä»¶
        signal_files = [f for f in os.listdir('.') if f.startswith('signals_e2e_') and f.endswith('.csv')]
        latest_signal_file = max(signal_files) if signal_files else None
        
        if not latest_signal_file:
            print("âŒ æœªæ‰¾åˆ°ä¿¡å·æ–‡ä»¶")
            return
            
        signals_df = pd.read_csv(latest_signal_file)
        signals_df['date'] = pd.to_datetime(signals_df['date'])
        print(f"ä½¿ç”¨ä¿¡å·æ–‡ä»¶: {latest_signal_file}")
    except Exception as e:
        print(f"âŒ åŠ è½½ä¿¡å·æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    # åŠ è½½ä»·æ ¼æ•°æ®
    data = load_all_symbols_data()
    
    print(f"ä¿¡å·æ•°æ®: {len(signals_df)}æ¡")
    print(f"åˆ†ææœŸé—´: {signals_df['date'].min()} è‡³ {signals_df['date'].max()}")
    
    # ç­›é€‰ä¿¡å·æœŸæ•°æ®
    signal_period_df = signals_df[signals_df['phase'] == 'signal_period'].copy()
    print(f"ä¿¡å·æœŸæ•°æ®: {len(signal_period_df)}æ¡")
    
    # åˆ†æå„é…å¯¹
    pairs = signal_period_df['pair'].unique()
    results = []
    
    print(f"\nğŸ” åˆ†é…å¯¹åˆ†æ ({len(pairs)}ä¸ªé…å¯¹):")
    
    for pair in pairs[:10]:  # åˆ†æå‰10ä¸ªé…å¯¹
        pair_data = signal_period_df[signal_period_df['pair'] == pair].copy()
        pair_data = pair_data.sort_values('date')
        
        if len(pair_data) < 100:
            continue
            
        # è·å–Z>2çš„ä¿¡å·ç‚¹
        z_gt2_signals = pair_data[np.abs(pair_data['z_score']) > 2.0].copy()
        
        if len(z_gt2_signals) < 5:
            print(f"  {pair}: Z>2ä¿¡å·å¤ªå°‘({len(z_gt2_signals)}ä¸ª)ï¼Œè·³è¿‡")
            continue
        
        print(f"\n=== {pair} ===")
        print(f"æ€»ä¿¡å·ç‚¹: {len(pair_data)}, Z>2ä¿¡å·: {len(z_gt2_signals)}ä¸ª ({len(z_gt2_signals)/len(pair_data)*100:.1f}%)")
        
        # è·å–ä»·æ ¼æ•°æ®
        symbol_x = pair_data['symbol_x'].iloc[0]
        symbol_y = pair_data['symbol_y'].iloc[0]
        
        # è®¡ç®—å„Z>2ä¿¡å·ç‚¹çš„åç»­å›å½’æ”¶ç›Š
        forward_returns = []
        signal_types = []
        z_values = []
        
        for _, signal_row in z_gt2_signals.iterrows():
            signal_date = signal_row['date']
            z_score = signal_row['z_score']
            
            # æ‰¾åˆ°ä¿¡å·æ—¥æœŸåçš„5ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
            future_dates = pair_data[pair_data['date'] > signal_date]['date'].head(5)
            
            if len(future_dates) < 3:  # è‡³å°‘éœ€è¦3ä¸ªåç»­ç‚¹
                continue
                
            # è·å–ä¿¡å·ç‚¹å’Œåç»­ç‚¹çš„ä»·æ ¼
            try:
                signal_x = data.loc[signal_date, symbol_x]
                signal_y = data.loc[signal_date, symbol_y]
                
                # è®¡ç®—åç»­å‡ å¤©çš„å›å½’æ”¶ç›Š
                daily_returns = []
                for future_date in future_dates:
                    try:
                        future_x = data.loc[future_date, symbol_x]
                        future_y = data.loc[future_date, symbol_y]
                        
                        # è®¡ç®—ä»·æ ¼å˜åŒ–
                        delta_x = future_x - signal_x
                        delta_y = future_y - signal_y
                        
                        # æ ¹æ®Z-scoreæ–¹å‘è®¡ç®—å›å½’æ”¶ç›Š
                        # Z<-2.0: é¢„æœŸä»·å·®å›å½’(æ”¶æ•›), long Y short X
                        # Z>+2.0: é¢„æœŸä»·å·®å›å½’(æ”¶æ•›), short Y long X
                        if z_score < -2.0:
                            # Long Y, Short X: æ”¶ç›Š = delta_y - beta*delta_x
                            regression_return = delta_y - signal_row['beta'] * delta_x
                        else:  # z_score > +2.0
                            # Short Y, Long X: æ”¶ç›Š = beta*delta_x - delta_y  
                            regression_return = signal_row['beta'] * delta_x - delta_y
                        
                        daily_returns.append(regression_return)
                        
                    except:
                        continue
                
                if daily_returns:
                    # è®¡ç®—å¹³å‡å›å½’æ”¶ç›Š
                    avg_return = np.mean(daily_returns)
                    forward_returns.append(avg_return)
                    signal_types.append('long' if z_score < -2.0 else 'short')
                    z_values.append(abs(z_score))
                    
            except:
                continue
        
        if len(forward_returns) < 5:
            print(f"  å¯åˆ†æä¿¡å·ä¸è¶³({len(forward_returns)}ä¸ª)")
            continue
        
        forward_returns = np.array(forward_returns)
        z_values = np.array(z_values)
        
        # ç»Ÿè®¡åˆ†æ
        positive_returns = np.sum(forward_returns > 0)
        negative_returns = np.sum(forward_returns < 0)
        zero_returns = len(forward_returns) - positive_returns - negative_returns
        
        mean_return = np.mean(forward_returns)
        std_return = np.std(forward_returns)
        
        # tæ£€éªŒï¼šæ”¶ç›Šæ˜¯å¦æ˜¾è‘—å¤§äº0
        t_stat, p_value = stats.ttest_1samp(forward_returns, 0)
        is_significant = p_value < 0.05 and mean_return > 0
        
        print(f"  Z>1.5ä¿¡å·åˆ†æ:")
        print(f"    æœ‰æ•ˆä¿¡å·: {len(forward_returns)}ä¸ª")
        print(f"    æ­£æ”¶ç›Š: {positive_returns}ä¸ª ({positive_returns/len(forward_returns)*100:.1f}%)")
        print(f"    è´Ÿæ”¶ç›Š: {negative_returns}ä¸ª ({negative_returns/len(forward_returns)*100:.1f}%)")
        print(f"    é›¶æ”¶ç›Š: {zero_returns}ä¸ª")
        print(f"  æ”¶ç›Šç»Ÿè®¡:")
        print(f"    å¹³å‡æ”¶ç›Š: {mean_return:.4f}")
        print(f"    æ”¶ç›Šæ ‡å‡†å·®: {std_return:.4f}")
        print(f"    æ”¶ç›Štæ£€éªŒ: t={t_stat:.3f}, p={p_value:.4f}")
        print(f"    æ˜¾è‘—æ€§: {'âœ… æ˜¾è‘—>0' if is_significant else 'âŒ ä¸æ˜¾è‘—' if mean_return > 0 else 'âŒ è´Ÿæ”¶ç›Š'}")
        
        # IRè®¡ç®—
        ir = mean_return / (std_return + 1e-8)
        print(f"    ä¿¡æ¯æ¯”ç‡: {ir:.3f}")
        
        results.append({
            'pair': pair,
            'total_signals': len(z_gt2_signals),
            'valid_signals': len(forward_returns),
            'positive_ratio': positive_returns / len(forward_returns),
            'mean_return': mean_return,
            'std_return': std_return,
            't_stat': t_stat,
            'p_value': p_value,
            'is_significant': is_significant,
            'ir': ir
        })
    
    # æ€»ç»“åˆ†æ
    if results:
        print(f"\nğŸ“Š æ€»ä½“åˆ†æç»“æœ:")
        print("=" * 70)
        
        results_df = pd.DataFrame(results)
        
        # æ•´ä½“ç»Ÿè®¡
        total_valid_signals = results_df['valid_signals'].sum()
        positive_pairs = len(results_df[results_df['mean_return'] > 0])
        significant_pairs = len(results_df[results_df['is_significant']])
        
        print(f"åˆ†æé…å¯¹æ•°: {len(results_df)}ä¸ª")
        print(f"æ€»æœ‰æ•ˆZ>1.5ä¿¡å·: {total_valid_signals}ä¸ª")
        print(f"å¹³å‡æ”¶ç›Š>0çš„é…å¯¹: {positive_pairs}/{len(results_df)} ({positive_pairs/len(results_df)*100:.1f}%)")
        print(f"æ”¶ç›Šæ˜¾è‘—>0çš„é…å¯¹: {significant_pairs}/{len(results_df)} ({significant_pairs/len(results_df)*100:.1f}%)")
        
        # åŠ æƒå¹³å‡æ”¶ç›Š
        weights = results_df['valid_signals'].values
        weighted_avg_return = np.average(results_df['mean_return'].values, weights=weights)
        
        print(f"\næ•´ä½“è¡¨ç°:")
        print(f"åŠ æƒå¹³å‡æ”¶ç›Š: {weighted_avg_return:.4f}")
        print(f"å¹³å‡IR: {results_df['ir'].mean():.3f}")
        print(f"æœ€ä½³é…å¯¹IR: {results_df['ir'].max():.3f}")
        
        # æ˜¾ç¤ºæœ€å¥½å’Œæœ€å·®çš„é…å¯¹
        print(f"\nğŸ† è¡¨ç°æœ€ä½³é…å¯¹:")
        best_pairs = results_df.nlargest(3, 'ir')
        for _, row in best_pairs.iterrows():
            print(f"  {row['pair']}: å¹³å‡æ”¶ç›Š={row['mean_return']:.4f}, IR={row['ir']:.3f}, "
                  f"èƒœç‡={row['positive_ratio']*100:.1f}%")
        
        print(f"\nâš ï¸ éœ€è¦å…³æ³¨é…å¯¹:")
        worst_pairs = results_df.nsmallest(3, 'mean_return')
        for _, row in worst_pairs.iterrows():
            print(f"  {row['pair']}: å¹³å‡æ”¶ç›Š={row['mean_return']:.4f}, IR={row['ir']:.3f}, "
                  f"èƒœç‡={row['positive_ratio']*100:.1f}%")
        
        # æ ¸å¿ƒç»“è®º
        print(f"\nğŸ¯ æ ¸å¿ƒç»“è®º:")
        if weighted_avg_return > 0:
            print(f"âœ… Z>1.5ä¿¡å·æ•´ä½“å›å½’æ”¶ç›Šä¸ºæ­£: {weighted_avg_return:.4f}")
        else:
            print(f"âŒ Z>1.5ä¿¡å·æ•´ä½“å›å½’æ”¶ç›Šä¸ºè´Ÿ: {weighted_avg_return:.4f}")
            
        if significant_pairs >= len(results_df) * 0.5:
            print(f"âœ… è¿‡åŠé…å¯¹({significant_pairs}/{len(results_df)})æ”¶ç›Šæ˜¾è‘—å¤§äº0")
        else:
            print(f"âš ï¸ ä»…{significant_pairs}/{len(results_df)}ä¸ªé…å¯¹æ”¶ç›Šæ˜¾è‘—å¤§äº0")
        
        return results_df
    else:
        print("âŒ æ²¡æœ‰è¶³å¤Ÿæ•°æ®è¿›è¡Œåˆ†æ")
        return None

if __name__ == "__main__":
    results = analyze_regression_returns()