#!/usr/bin/env python3
"""
ä¿®å¤ä¿¡å·ç”Ÿæˆé—®é¢˜çš„ç³»ç»Ÿåˆ†æè„šæœ¬
"""
import pandas as pd
import numpy as np
from lib.data import load_all_symbols_data
import os

def analyze_xy_assignment_problem():
    """åˆ†æX/Yåˆ†é…é—®é¢˜"""
    print("=== åˆ†æX/Yåˆ†é…é—®é¢˜ ===")
    
    # åŠ è½½æ•°æ®
    data = load_all_symbols_data()
    recent_data = data['2024-01-01':]
    
    # è®¡ç®—æ‰€æœ‰å“ç§çš„æ³¢åŠ¨ç‡
    volatilities = recent_data.std().sort_values()
    print("2024å¹´è‡³ä»Šå„å“ç§æ³¢åŠ¨ç‡ï¼ˆä»ä½åˆ°é«˜ï¼‰:")
    for symbol, vol in volatilities.items():
        print(f"  {symbol}: {vol:.6f}")
    
    # æ£€æŸ¥å½“å‰ä¿¡å·æ–‡ä»¶ä¸­çš„X/Yåˆ†é…
    signal_files = [f for f in os.listdir('.') if f.startswith('signals_e2e_') and f.endswith('.csv')]
    if signal_files:
        latest_signal_file = max(signal_files)
        signals_df = pd.read_csv(latest_signal_file)
        
        print(f"\nå½“å‰ä¿¡å·æ–‡ä»¶ä¸­çš„X/Yåˆ†é…:")
        pairs_info = []
        for pair in signals_df['pair'].unique()[:10]:  # æ£€æŸ¥å‰10ä¸ªé…å¯¹
            pair_data = signals_df[signals_df['pair'] == pair].iloc[0]
            symbol_x = pair_data['symbol_x']
            symbol_y = pair_data['symbol_y']
            
            vol_x = volatilities[symbol_x] if symbol_x in volatilities else None
            vol_y = volatilities[symbol_y] if symbol_y in volatilities else None
            
            correct_assignment = vol_x < vol_y if (vol_x and vol_y) else None
            
            pairs_info.append({
                'pair': pair,
                'symbol_x': symbol_x,
                'symbol_y': symbol_y,
                'vol_x': vol_x,
                'vol_y': vol_y,
                'correct_assignment': correct_assignment
            })
        
        pairs_df = pd.DataFrame(pairs_info)
        print(pairs_df)
        
        # ç»Ÿè®¡é”™è¯¯åˆ†é…
        wrong_assignments = pairs_df[pairs_df['correct_assignment'] == False]
        print(f"\nâŒ é”™è¯¯åˆ†é…çš„é…å¯¹æ•°é‡: {len(wrong_assignments)} / {len(pairs_df)}")
        
        return pairs_df, volatilities
    
    return None, volatilities

def analyze_beta_calculation_logic():
    """åˆ†æÎ²å€¼è®¡ç®—é€»è¾‘"""
    print("\n=== åˆ†æÎ²å€¼è®¡ç®—é€»è¾‘ ===")
    
    # æ‰‹åŠ¨è®¡ç®—AG-NIçš„æ­£ç¡®Î²å€¼
    data = load_all_symbols_data()
    
    # æ ¹æ®æ³¢åŠ¨ç‡æ­£ç¡®åˆ†é…ï¼šNIåº”è¯¥ä½œä¸ºXï¼ˆä½æ³¢åŠ¨ç‡ï¼‰ï¼ŒAGåº”è¯¥ä½œä¸ºYï¼ˆé«˜æ³¢åŠ¨ç‡ï¼‰
    ag_prices = data['AG'].dropna()
    ni_prices = data['NI'].dropna()
    
    # å¯¹é½æ•°æ®
    common_dates = ag_prices.index.intersection(ni_prices.index)
    ag_aligned = ag_prices[common_dates]
    ni_aligned = ni_prices[common_dates]
    
    print(f"æ•°æ®å¯¹é½åé•¿åº¦: {len(common_dates)}")
    
    # è®¡ç®—å¯¹æ•°ä»·æ ¼
    log_ag = np.log(ag_aligned)
    log_ni = np.log(ni_aligned)
    
    # ä½¿ç”¨æœ€è¿‘1å¹´æ•°æ®è¿›è¡Œå›å½’
    recent_start = '2024-01-01'
    recent_ag = log_ag[recent_start:]
    recent_ni = log_ni[recent_start:]
    
    if len(recent_ag) > 0 and len(recent_ni) > 0:
        # æƒ…å†µ1: æŒ‰å½“å‰åˆ†é… AG(X) vs NI(Y), Î² = Î”log(NI)/Î”log(AG)
        beta_current_assignment = np.cov(recent_ag, recent_ni)[0,1] / np.var(recent_ag)
        print(f"å½“å‰åˆ†é… AG(X)->NI(Y) çš„Î²: {beta_current_assignment:.6f}")
        
        # æƒ…å†µ2: æ­£ç¡®åˆ†é… NI(X) vs AG(Y), Î² = Î”log(AG)/Î”log(NI) 
        beta_correct_assignment = np.cov(recent_ni, recent_ag)[0,1] / np.var(recent_ni)
        print(f"æ­£ç¡®åˆ†é… NI(X)->AG(Y) çš„Î²: {beta_correct_assignment:.6f}")
        
        # ä½¿ç”¨OLSéªŒè¯
        from sklearn.linear_model import LinearRegression
        
        # å½“å‰åˆ†é…çš„OLS
        reg_current = LinearRegression()
        reg_current.fit(recent_ag.values.reshape(-1,1), recent_ni.values)
        beta_ols_current = reg_current.coef_[0]
        print(f"å½“å‰åˆ†é… OLS Î²: {beta_ols_current:.6f}")
        
        # æ­£ç¡®åˆ†é…çš„OLS
        reg_correct = LinearRegression()
        reg_correct.fit(recent_ni.values.reshape(-1,1), recent_ag.values)
        beta_ols_correct = reg_correct.coef_[0]
        print(f"æ­£ç¡®åˆ†é… OLS Î²: {beta_ols_correct:.6f}")
        
        return {
            'beta_current': beta_current_assignment,
            'beta_correct': beta_correct_assignment,
            'beta_ols_current': beta_ols_current,
            'beta_ols_correct': beta_ols_correct
        }
    
    return None

def check_kalman_initialization_logic():
    """æ£€æŸ¥Kalmanæ»¤æ³¢åˆå§‹åŒ–é€»è¾‘"""
    print("\n=== æ£€æŸ¥Kalmanæ»¤æ³¢åˆå§‹åŒ–é€»è¾‘ ===")
    
    # æ£€æŸ¥signal_generation.pyä¸­çš„åˆå§‹åŒ–é€»è¾‘
    try:
        with open('lib/signal_generation.py', 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æŸ¥æ‰¾å…³é”®çš„åˆå§‹åŒ–ä»£ç æ®µ
        lines = content.split('\n')
        
        # æŸ¥æ‰¾warm_up_olsæ–¹æ³•
        in_warmup_method = False
        warmup_lines = []
        
        for i, line in enumerate(lines):
            if 'def warm_up_ols' in line:
                in_warmup_method = True
                warmup_lines.append(f"{i+1:4d}: {line}")
            elif in_warmup_method:
                if line.strip().startswith('def ') and 'warm_up_ols' not in line:
                    break
                warmup_lines.append(f"{i+1:4d}: {line}")
        
        print("warm_up_ols æ–¹æ³•å…³é”®ä»£ç :")
        for line in warmup_lines[:20]:  # æ˜¾ç¤ºå‰20è¡Œ
            print(line)
            
        # æ£€æŸ¥Î²å€¼ç¬¦å·å¤„ç†
        if 'np.sign' in content or 'abs(' in content:
            print("\nâš ï¸ å‘ç°ç¬¦å·å¤„ç†ç›¸å…³ä»£ç ")
        else:
            print("\nâœ… æœªå‘ç°ç¬¦å·å¼ºåˆ¶å¤„ç†ä»£ç ")
            
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–signal_generation.py: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” ç³»ç»Ÿåˆ†æä¿¡å·ç”Ÿæˆé—®é¢˜")
    print("=" * 50)
    
    # 1. åˆ†æX/Yåˆ†é…é—®é¢˜
    pairs_df, volatilities = analyze_xy_assignment_problem()
    
    # 2. åˆ†æÎ²å€¼è®¡ç®—é€»è¾‘
    beta_results = analyze_beta_calculation_logic()
    
    # 3. æ£€æŸ¥Kalmanåˆå§‹åŒ–é€»è¾‘
    check_kalman_initialization_logic()
    
    # 4. æ€»ç»“é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
    print("\n" + "=" * 50)
    print("ğŸ¯ é—®é¢˜æ€»ç»“å’Œè§£å†³æ–¹æ¡ˆ:")
    
    if pairs_df is not None:
        wrong_count = len(pairs_df[pairs_df['correct_assignment'] == False])
        total_count = len(pairs_df)
        if wrong_count > 0:
            print(f"1. âŒ X/Yåˆ†é…é—®é¢˜: {wrong_count}/{total_count} é…å¯¹åˆ†é…é”™è¯¯")
            print("   è§£å†³æ–¹æ¡ˆ: ä¿®æ”¹åæ•´åˆ†æé˜¶æ®µçš„é…å¯¹é€»è¾‘ï¼Œä½æ³¢åŠ¨ç‡ä½œä¸ºX")
        else:
            print("1. âœ… X/Yåˆ†é…æ­£ç¡®")
    
    if beta_results:
        print(f"2. âŒ Î²å€¼è®¡ç®—é—®é¢˜: å½“å‰={beta_results['beta_ols_current']:.6f}, åº”è¯¥={beta_results['beta_ols_correct']:.6f}")
        print("   è§£å†³æ–¹æ¡ˆ: é‡æ–°è¿è¡Œåæ•´åˆ†æï¼Œä½¿ç”¨æ­£ç¡®çš„X/Yåˆ†é…")
    
    print("3. âš ï¸ Kalmanæ»¤æ³¢åˆå§‹åŒ–: éœ€è¦ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„åˆå§‹Î²å€¼")
    print("   è§£å†³æ–¹æ¡ˆ: ä¿®å¤åæ•´åˆ†æåé‡æ–°ç”Ÿæˆä¿¡å·")

if __name__ == "__main__":
    main()