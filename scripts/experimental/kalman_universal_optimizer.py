#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é€šç”¨Kalmanæ»¤æ³¢å‚æ•°ä¼˜åŒ–å™¨
æŒ‰ç…§ä¸¥æ ¼å·¥ç¨‹æ ‡å‡†ï¼Œæ”¯æŒå¤šé…å¯¹éªŒè¯
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from lib.data import load_all_symbols_data
from sklearn.linear_model import LinearRegression
from statsmodels.tsa.stattools import adfuller
from statsmodels.stats.diagnostic import acorr_ljungbox
import warnings
warnings.filterwarnings('ignore')

class KalmanOptimizer:
    """é€šç”¨Kalmanæ»¤æ³¢å‚æ•°ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.quality_standards = {
            'mean_strict': 0.10,
            'mean_loose': 0.15,
            'std_strict': (0.95, 1.05),
            'std_loose': (0.90, 1.10),
            'std_hetero': (0.85, 1.20),
            'acf_threshold': 0.1,
            'ljung_box_threshold': 0.20,
            'energy_ratio_strict': (0.90, 1.10),
            'energy_ratio_loose': (0.85, 1.15),
            'extreme_3sigma': 0.01,
            'extreme_4sigma': 0.002
        }
    
    def load_pair_data(self, x_symbol, y_symbol, log_prices=True):
        """åŠ è½½é…å¯¹æ•°æ®"""
        df = load_all_symbols_data()
        
        if log_prices:
            x_data = np.log(df[x_symbol].dropna())
            y_data = np.log(df[y_symbol].dropna())
        else:
            x_data = df[x_symbol].dropna()
            y_data = df[y_symbol].dropna()
        
        common_dates = x_data.index.intersection(y_data.index)
        x_aligned = x_data.loc[common_dates]
        y_aligned = y_data.loc[common_dates]
        
        return x_aligned, y_aligned
    
    def estimate_initial_params(self, x_data, y_data, window=300):
        """ä¼°è®¡åˆå§‹å‚æ•°ï¼ˆé€šç”¨æ–¹æ³•ï¼Œå‡å°‘è¿‡æ‹Ÿåˆï¼‰"""
        # ä½¿ç”¨è¾ƒé•¿çª—å£ä¼°è®¡ç¨³å®šçš„Î²
        reg = LinearRegression()
        reg.fit(x_data[:window].values.reshape(-1, 1), y_data[:window].values)
        beta0 = reg.coef_[0]
        c0 = reg.intercept_
        
        # è®¡ç®—åˆ›æ–°ç»Ÿè®¡ï¼ˆä½¿ç”¨æ ·æœ¬å¤–æ•°æ®é¿å…è¿‡æ‹Ÿåˆï¼‰
        test_start = window
        test_end = min(window + 100, len(x_data))
        
        innovations = []
        for i in range(test_start, test_end):
            v = y_data.iloc[i] - (beta0 * x_data.iloc[i] + c0)
            innovations.append(v)
        
        v_var = np.var(innovations)
        v_mean = np.mean(innovations)
        
        # ç³»ç»Ÿæ€§åç§»è°ƒæ•´
        if abs(v_mean) > 0.001:
            c0_adjusted = c0 + v_mean
        else:
            c0_adjusted = c0
            
        return beta0, c0_adjusted, v_var
    
    def calculate_universal_params(self, x_data, y_data, v_var):
        """è®¡ç®—é€šç”¨å‚æ•°ï¼ˆå‡å°‘é­”æ³•æ•°å­—ï¼‰"""
        avg_x = np.mean(x_data[300:400])  # ä½¿ç”¨ä¸­æ®µæ•°æ®
        
        # æ ¸å¿ƒæ€è·¯ï¼šè®©Sæ¥è¿‘åˆ›æ–°æ–¹å·®ï¼Œä½†ç”¨æ›´ä¿å®ˆçš„å‚æ•°
        # å‡å°‘ç¡¬ç¼–ç ï¼Œå¢åŠ ç†è®ºä¾æ®
        
        # åŸºç¡€å‚æ•°ï¼šè®©æœŸæœ›çš„Så€¼æ¥è¿‘åˆ›æ–°æ–¹å·®
        base_S = v_var * 1.0  # ä¸ç”¨1.1ï¼Œç›´æ¥ç”¨1.0æ›´ä¿å®ˆ
        
        # Rå’ŒPçš„åˆ†é…ï¼šåŸºäºç³»ç»Ÿè¾¨è¯†ç†è®º
        # Rä¸»å¯¼ï¼ˆè§‚æµ‹å™ªå£°ï¼‰ï¼ŒPæä¾›é€‚åº”æ€§
        R = base_S * 0.8      # Ræ‰¿æ‹…80%ï¼ˆå‡å°‘åˆ°0.8ï¼‰
        P_contribution = base_S * 0.2 / (avg_x ** 2)
        
        # Qçš„è®¾å®šï¼šåŸºäºÎ²çš„é¢„æœŸå˜åŒ–ç‡
        # å‡è®¾Î²æ¯å¹´å˜åŒ–ä¸è¶…è¿‡5%ï¼Œæ¯å¤©å˜åŒ–çº¦0.02%
        daily_beta_change = 0.0002  # 0.02%
        Q_beta = (daily_beta_change * abs(x_data.mean())) ** 2 * P_contribution
        Q_c = R * 1e-6
        
        return {
            'R': R,
            'Q_beta': Q_beta, 
            'Q_c': Q_c,
            'P_target': P_contribution,
            'base_S': base_S
        }
    
    def run_kalman_filter(self, x_data, y_data, beta0, c0, params, start_idx=300):
        """è¿è¡ŒKalmanæ»¤æ³¢"""
        # åˆå§‹åŒ–
        beta_kf = beta0
        c_kf = c0
        P = np.diag([params['P_target'], params['P_target'] * 0.1])
        Q = np.diag([params['Q_beta'], params['Q_c']])
        R = params['R']
        
        results = []
        
        for i in range(start_idx, len(x_data)):
            x_t = x_data.iloc[i]
            y_t = y_data.iloc[i]
            
            # é¢„æµ‹
            P_pred = P + Q
            H = np.array([[x_t, 1.0]])
            y_pred = beta_kf * x_t + c_kf
            
            # åˆ›æ–°
            v = y_t - y_pred
            S = float(H @ P_pred @ H.T + R)
            S = max(S, 1e-12)
            z = v / np.sqrt(S)
            
            # èƒ½é‡æ¯”
            r_ratio = (v ** 2) / S
            
            results.append({
                'date': x_data.index[i],
                'v': v,
                'S': S,
                'z': z,
                'r_ratio': r_ratio,
                'beta': beta_kf,
                'c': c_kf
            })
            
            # æ›´æ–°
            K = (P_pred @ H.T) / S
            update_vec = (K * v).ravel()
            beta_kf += update_vec[0]
            c_kf += update_vec[1]
            
            I_KH = np.eye(2) - K @ H
            P = I_KH @ P_pred @ I_KH.T + K @ np.array([[R]]) @ K.T
        
        return pd.DataFrame(results).set_index('date')
    
    def evaluate_quality(self, results_df, pair_name=""):
        """æŒ‰ç…§å·¥ç¨‹æ ‡å‡†è¯„ä¼°è´¨é‡"""
        z_scores = results_df['z'].values
        r_ratios = results_df['r_ratio'].values
        
        # 1. å‡å€¼æ£€æŸ¥
        z_mean = np.mean(z_scores)
        z_abs_mean = np.abs(z_mean)
        mean_strict_ok = z_abs_mean <= self.quality_standards['mean_strict']
        mean_loose_ok = z_abs_mean <= self.quality_standards['mean_loose']
        
        # 2. æ ‡å‡†å·®æ£€æŸ¥
        z_std = np.std(z_scores)
        std_strict_ok = (self.quality_standards['std_strict'][0] <= z_std <= 
                        self.quality_standards['std_strict'][1])
        std_loose_ok = (self.quality_standards['std_loose'][0] <= z_std <= 
                       self.quality_standards['std_loose'][1])
        std_hetero_ok = (self.quality_standards['std_hetero'][0] <= z_std <= 
                        self.quality_standards['std_hetero'][1])
        
        # 3. è‡ªç›¸å…³æ£€æŸ¥
        from statsmodels.tsa.stattools import acf
        try:
            acf_values = acf(z_scores, nlags=5, fft=False)[1:6]  # æ’é™¤lag=0
            acf_ok = np.all(np.abs(acf_values) < self.quality_standards['acf_threshold'])
            max_acf = np.max(np.abs(acf_values))
        except:
            acf_ok = False
            max_acf = np.nan
        
        # 4. Ljung-Boxæ£€æŸ¥
        try:
            lb_result = acorr_ljungbox(z_scores, lags=5, return_df=True)
            lb_pvalue = lb_result.iloc[-1]['lb_pvalue']  # å–lag=5çš„på€¼
            lb_ok = lb_pvalue > self.quality_standards['ljung_box_threshold']
        except:
            lb_ok = False
            lb_pvalue = np.nan
        
        # 5. èƒ½é‡æ¯”æ£€æŸ¥
        r_mean = np.mean(r_ratios)
        r_strict_ok = (self.quality_standards['energy_ratio_strict'][0] <= r_mean <= 
                      self.quality_standards['energy_ratio_strict'][1])
        r_loose_ok = (self.quality_standards['energy_ratio_loose'][0] <= r_mean <= 
                     self.quality_standards['energy_ratio_loose'][1])
        
        # 6. æå€¼é¢‘ç‡æ£€æŸ¥
        extreme_3sigma = np.mean(np.abs(z_scores) > 3)
        extreme_4sigma = np.mean(np.abs(z_scores) > 4)
        extreme_3_ok = extreme_3sigma <= self.quality_standards['extreme_3sigma']
        extreme_4_ok = extreme_4sigma <= self.quality_standards['extreme_4sigma']
        
        # ç»¼åˆè¯„åˆ†
        strict_score = sum([mean_strict_ok, std_strict_ok, acf_ok, lb_ok, r_strict_ok, extreme_3_ok, extreme_4_ok])
        loose_score = sum([mean_loose_ok, std_loose_ok, acf_ok, lb_ok, r_loose_ok, extreme_3_ok, extreme_4_ok])
        hetero_score = sum([mean_loose_ok, std_hetero_ok, acf_ok, lb_ok, r_loose_ok, extreme_3_ok, extreme_4_ok])
        
        quality_report = {
            'pair_name': pair_name,
            'z_mean': z_mean,
            'z_std': z_std,
            'z_abs_mean': z_abs_mean,
            'r_mean': r_mean,
            'max_acf': max_acf,
            'lb_pvalue': lb_pvalue,
            'extreme_3sigma': extreme_3sigma,
            'extreme_4sigma': extreme_4sigma,
            'mean_strict_ok': mean_strict_ok,
            'mean_loose_ok': mean_loose_ok,
            'std_strict_ok': std_strict_ok,
            'std_loose_ok': std_loose_ok,
            'std_hetero_ok': std_hetero_ok,
            'acf_ok': acf_ok,
            'lb_ok': lb_ok,
            'r_strict_ok': r_strict_ok,
            'r_loose_ok': r_loose_ok,
            'extreme_3_ok': extreme_3_ok,
            'extreme_4_ok': extreme_4_ok,
            'strict_score': strict_score,
            'loose_score': loose_score,
            'hetero_score': hetero_score,
            'max_possible_score': 7
        }
        
        return quality_report
    
    def optimize_pair(self, x_symbol, y_symbol, pair_name=None):
        """ä¼˜åŒ–å•ä¸ªé…å¯¹"""
        if pair_name is None:
            pair_name = f"{x_symbol}-{y_symbol}"
        
        print(f"\n{'='*60}")
        print(f"ä¼˜åŒ–é…å¯¹: {pair_name}")
        print(f"{'='*60}")
        
        # 1. åŠ è½½æ•°æ®
        x_data, y_data = self.load_pair_data(x_symbol, y_symbol)
        print(f"æ•°æ®èŒƒå›´: {x_data.index[0].date()} åˆ° {x_data.index[-1].date()}")
        print(f"æ ·æœ¬æ•°: {len(x_data)}")
        
        # 2. ä¼°è®¡åˆå§‹å‚æ•°
        beta0, c0, v_var = self.estimate_initial_params(x_data, y_data)
        print(f"åˆå§‹å‚æ•°: Î²={beta0:.6f}, c={c0:.6f}, v_var={v_var:.8f}")
        
        # 3. è®¡ç®—é€šç”¨å‚æ•°
        params = self.calculate_universal_params(x_data, y_data, v_var)
        print(f"Kalmanå‚æ•°: R={params['R']:.6f}, Q_Î²={params['Q_beta']:.2e}")
        
        # 4. è¿è¡ŒKalmanæ»¤æ³¢
        results = self.run_kalman_filter(x_data, y_data, beta0, c0, params)
        print(f"æ»¤æ³¢å®Œæˆ: å¤„ç†{len(results)}ä¸ªæ ·æœ¬")
        
        # 5. è¯„ä¼°è´¨é‡
        quality = self.evaluate_quality(results, pair_name)
        
        return {
            'pair_name': pair_name,
            'params': params,
            'results': results,
            'quality': quality,
            'data': {'x_data': x_data, 'y_data': y_data}
        }
    
    def print_quality_report(self, quality):
        """æ‰“å°è´¨é‡æŠ¥å‘Š"""
        print(f"\nğŸ“Š è´¨é‡è¯„ä¼°æŠ¥å‘Š: {quality['pair_name']}")
        print(f"{'='*50}")
        
        # æ ¸å¿ƒæŒ‡æ ‡
        print(f"å‡å€¼: {quality['z_mean']:7.4f} (|zÌ„|={quality['z_abs_mean']:.4f})")
        mean_status = "âœ…ä¸¥æ ¼" if quality['mean_strict_ok'] else ("âœ…å®½æ¾" if quality['mean_loose_ok'] else "âŒè¶…æ ‡")
        print(f"      æ ‡å‡†: â‰¤0.10(ä¸¥æ ¼) / â‰¤0.15(å®½æ¾) â†’ {mean_status}")
        
        print(f"æ ‡å‡†å·®: {quality['z_std']:6.4f}")
        if quality['std_strict_ok']:
            std_status = "âœ…ä¸¥æ ¼åˆæ ¼"
        elif quality['std_loose_ok']:
            std_status = "âœ…å®½æ¾åˆæ ¼"
        elif quality['std_hetero_ok']:
            std_status = "âœ…å¼‚æ–¹å·®åˆæ ¼"
        else:
            std_status = "âŒä¸åˆæ ¼"
        print(f"      æ ‡å‡†: 0.95-1.05(ä¸¥æ ¼) / 0.90-1.10(å®½æ¾) / 0.85-1.20(å¼‚æ–¹å·®) â†’ {std_status}")
        
        # è‡ªç›¸å…³å’Œç‹¬ç«‹æ€§
        print(f"è‡ªç›¸å…³: max|ACF|={quality['max_acf']:.4f} â†’ {'âœ…' if quality['acf_ok'] else 'âŒ'}")
        print(f"Ljung-Box: p={quality['lb_pvalue']:.4f} â†’ {'âœ…' if quality['lb_ok'] else 'âŒ'}")
        
        # èƒ½é‡æ¯”
        print(f"èƒ½é‡æ¯”: rÌ„={quality['r_mean']:.4f}")
        r_status = "âœ…ä¸¥æ ¼" if quality['r_strict_ok'] else ("âœ…å®½æ¾" if quality['r_loose_ok'] else "âŒè¶…æ ‡")
        print(f"      æ ‡å‡†: 1.00Â±0.10(ä¸¥æ ¼) / 1.00Â±0.15(å®½æ¾) â†’ {r_status}")
        
        # æå€¼é¢‘ç‡
        print(f"æå€¼é¢‘ç‡: |z|>3: {quality['extreme_3sigma']*100:.2f}% â†’ {'âœ…' if quality['extreme_3_ok'] else 'âŒ'}")
        print(f"         |z|>4: {quality['extreme_4sigma']*100:.2f}% â†’ {'âœ…' if quality['extreme_4_ok'] else 'âŒ'}")
        
        # ç»¼åˆè¯„åˆ†
        print(f"\nğŸ¯ ç»¼åˆè¯„åˆ†:")
        print(f"  ä¸¥æ ¼æ ‡å‡†: {quality['strict_score']}/{quality['max_possible_score']}")
        print(f"  å®½æ¾æ ‡å‡†: {quality['loose_score']}/{quality['max_possible_score']}")
        print(f"  å¼‚æ–¹å·®å®¹å¿: {quality['hetero_score']}/{quality['max_possible_score']}")
        
        # æœ€ç»ˆåˆ¤å®š
        if quality['strict_score'] >= 6:
            print("ğŸ† ä¸¥æ ¼æ ‡å‡†é€šè¿‡ï¼ç”Ÿäº§å¯ç”¨")
        elif quality['loose_score'] >= 6:
            print("âœ… å®½æ¾æ ‡å‡†é€šè¿‡ï¼å®ç”¨å¯è¡Œ")
        elif quality['hetero_score'] >= 6:
            print("âš ï¸ å¼‚æ–¹å·®å®¹å¿ä¸‹å‹‰å¼ºåˆæ ¼")
        else:
            print("âŒ æœªè¾¾æ ‡ï¼Œéœ€è¦å‚æ•°è°ƒæ•´")

def test_multiple_pairs():
    """æµ‹è¯•å¤šä¸ªé…å¯¹çš„é€šç”¨æ€§"""
    optimizer = KalmanOptimizer()
    
    # æµ‹è¯•é…å¯¹åˆ—è¡¨ï¼ˆé€‰æ‹©åæ•´æ€§å¼ºçš„ï¼‰
    test_pairs = [
        ('AL', 'ZN', 'AL-ZN'),   # ä¹‹å‰æµ‹è¯•çš„é…å¯¹
        ('CU', 'ZN', 'CU-ZN'),   # æœ‰è‰²é‡‘å±
        ('RB', 'HC', 'RB-HC'),   # é»‘è‰²ç³»
    ]
    
    results = {}
    
    for x_symbol, y_symbol, pair_name in test_pairs:
        try:
            result = optimizer.optimize_pair(x_symbol, y_symbol, pair_name)
            results[pair_name] = result
            optimizer.print_quality_report(result['quality'])
        except Exception as e:
            print(f"âŒ {pair_name} ä¼˜åŒ–å¤±è´¥: {str(e)}")
            continue
    
    # æ€»ç»“æŠ¥å‘Š
    print(f"\n{'='*80}")
    print("ğŸ¯ å¤šé…å¯¹é€šç”¨æ€§éªŒè¯æ€»ç»“")
    print(f"{'='*80}")
    
    summary_data = []
    for pair_name, result in results.items():
        q = result['quality']
        summary_data.append({
            'é…å¯¹': pair_name,
            'zÌ„': f"{q['z_mean']:.4f}",
            'Ïƒ(z)': f"{q['z_std']:.4f}",
            'rÌ„': f"{q['r_mean']:.3f}",
            'ä¸¥æ ¼': f"{q['strict_score']}/7",
            'å®½æ¾': f"{q['loose_score']}/7",
            'çŠ¶æ€': 'ğŸ†' if q['strict_score']>=6 else ('âœ…' if q['loose_score']>=6 else 'âŒ')
        })
    
    summary_df = pd.DataFrame(summary_data)
    print(summary_df.to_string(index=False))
    
    return results

if __name__ == '__main__':
    results = test_multiple_pairs()